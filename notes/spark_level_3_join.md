# ğŸš€ Spark Level 3 â€“ Internals

## BÃ i 1: DAG â€“ Stage â€“ Task (Cá»T LÃ•I Cá»¦A SPARK)

â— Náº¿u hiá»ƒu pháº§n nÃ y â†’ báº¡n vÆ°á»£t 90% ngÆ°á»i dÃ¹ng Spark

---

### 1ï¸âƒ£ Tá»•ng quan kiáº¿n trÃºc thá»±c thi Spark

**Spark Execution Flow:**

```mermaid
graph
Code[Code] --> B[Logical Plan]

B --> C[Physical Plan]

C --> D[Physical Plan]

D --> E[DAG]

E --> F[Stages]

F --> G[Tasks]

```

---

### 2ï¸âƒ£ DAG lÃ  gÃ¬?

**DAG (Directed Acyclic Graph) lÃ :**
- Äá»“ thá»‹ biá»ƒu diá»…n toÃ n bá»™ pipeline tÃ­nh toÃ¡n
- CÃ¡c node = transformation
- CÃ¡c cáº¡nh = dependency
- KhÃ´ng cÃ³ vÃ²ng láº·p

> ğŸ“Œ DAG Ä‘Æ°á»£c táº¡o KHI CÃ“ ACTION

---

### 3ï¸âƒ£ Stage lÃ  gÃ¬?

**Stage lÃ :**
- Má»™t táº­p cÃ¡c task cÃ³ thá»ƒ cháº¡y song song
- Bá»‹ chia cáº¯t bá»Ÿi SHUFFLE

**Quy táº¯c VÃ€NG:**

> Má»—i láº§n shuffle â†’ táº¡o stage má»›i

** VÃ­ dá»¥:**

```python
df.filter(...).select(...)   # Stage 1
df.groupBy(...).count()      # Stage 2 (shuffle)
```

---

### 4ï¸âƒ£ Task lÃ  gÃ¬?

**Task lÃ :**
- ÄÆ¡n vá»‹ nhá» nháº¥t Spark cÃ³ thá»ƒ thá»±c thi
- Má»™t task xá»­ lÃ½ má»™t partition
- Cháº¡y trÃªn má»™t executor

> ğŸ“Œ Sá»‘ task = sá»‘ partition trong stage

---

### 5ï¸âƒ£ VÃ­ dá»¥ THá»°C Táº¾

```python
df = spark.read.parquet("data")

df2 = df.filter("amount > 1000")      # Transformation
df3 = df2.groupBy("customer_id").sum("amount")  # Shuffle

df3.show()   # Action
```

#### DAG sáº½ lÃ :

**Stage 0:**
- Read
- Filter

**Stage 1:**
- Exchange (shuffle)
- HashAggregate

---

### 6ï¸âƒ£ VÃ¬ sao hiá»ƒu Stage quan trá»ng?

|**Váº¥n Ä‘á»**|**LiÃªn quan**|
|----------|-------------|
|Job cháº¡y cháº­m|Stage skew|
|Executor OOM|Task quÃ¡ lá»›n|
|Shuffle nhiá»u|Stage split|
|Tuning Spark|Stage-based|

---

## ğŸ§  CÃ‚U Há»I Báº®T BUá»˜C â€“ LEVEL 3 / BÃ€I 1

1. Khi nÃ o DAG Ä‘Æ°á»£c táº¡o?
> DAG Ä‘Æ°á»£c táº¡o khi Spark gáº·p má»™t ACTION
>>(vÃ­ dá»¥: show(), collect(), count(), write). TrÆ°á»›c Ä‘Ã³, Spark chá»‰ xÃ¢y dá»±ng Logical Plan vÃ  chÆ°a thá»±c thi báº¥t ká»³ phÃ©p tÃ­nh nÃ o.
2. Äiá»u gÃ¬ quyáº¿t Ä‘á»‹nh sá»‘ stage?
> Sá»‘ stage Ä‘Æ°á»£c quyáº¿t Ä‘á»‹nh bá»Ÿi sá»‘ láº§n shuffle.
>>Má»—i phÃ©p toÃ¡n gÃ¢y shuffle (Exchange) sáº½ táº¡o ra má»™t stage má»›i.

> ğŸ“Œ Tá»« khÃ³a chuáº©n: Stage boundary = Shuffle boundary
3. Sá»‘ task phá»¥ thuá»™c vÃ o yáº¿u tá»‘ nÃ o?
> Sá»‘ task trong má»™t stage báº±ng sá»‘ partition cá»§a dá»¯ liá»‡u trong stage Ä‘Ã³.
>> Má»—i task xá»­ lÃ½ Ä‘Ãºng 1 partition.
4. VÃ¬ sao Spark khÃ´ng thá»ƒ chia nhá» má»™t task Ä‘ang cháº¡y?
> Spark khÃ´ng thá»ƒ chia nhá» má»™t task Ä‘ang cháº¡y vÃ¬:
>>- Task lÃ  Ä‘Æ¡n vá»‹ thá»±c thi nhá» nháº¥t cá»§a Spark
>>- Task Ä‘Ã£ Ä‘Æ°á»£c gÃ¡n cho má»™t executor
>>- Spark khÃ´ng cÃ³ cÆ¡ cháº¿ preempt hoáº·c split task
>>>â†’ Náº¿u task bá»‹ skew, toÃ n bá»™ stage pháº£i chá»

> ğŸ“Œ Tá»« khÃ³a chuáº©n: Straggler task
5. VÃ¬ sao giáº£m shuffle giÃºp Spark nhanh hÆ¡n?
> Giáº£m shuffle giÃºp Spark nhanh hÆ¡n vÃ¬:
>>- Shuffle gÃ¢y I/O lá»›n (disk + network)
>>- Shuffle táº¡o thÃªm stage (barrier)
>>- Shuffle táº¡o nhiá»u task nhá», tá»‘n overhead
>>- Shuffle dá»… gÃ¢y skew vÃ  OOM

>ğŸ“Œ Shuffle lÃ  káº» thÃ¹ sá»‘ 1 cá»§a hiá»‡u nÄƒng Spark

---

## ğŸ Tá»”NG Káº¾T LEVEL 3 â€“ BÃ€I 1

ğŸ‘‰ Báº¡n Ä‘Ã£ náº¯m Cá»T LÃ•I **internals Spark**

ğŸ‘‰ Chá»‰ cáº§n nhá»›:

* DAG â†’ Stage â†’ Task
*	Shuffle = Stage boundary
*	Task = Ä‘Æ¡n vá»‹ khÃ´ng chia nhá»

---

# ğŸ”¥ LEVEL 3 â€“ BÃ€I 2

## Logical Plan vs Physical Plan

### â— ÄÃ¢y lÃ  pháº§n giÃºp báº¡n Ä‘á»c explain() nhÆ° senior / architect

---

## 1ï¸âƒ£ Logical Plan lÃ  gÃ¬?

**Logical Plan lÃ :**
- MÃ´ táº£ **"LÃ€M GÃŒ"**
- Äá»™c láº­p vá»›i cÃ¡ch thá»±c thi
- ÄÆ°á»£c xÃ¢y tá»« DataFrame / SQL

**VÃ­ dá»¥:**

```python
df.filter("amount > 1000").groupBy("country").sum()
```

**ğŸ‘‰ Logical plan chá»‰ nÃ³i:**

>Lá»c â†’ Group â†’ Sum

---

## 2ï¸âƒ£ Physical Plan lÃ  gÃ¬?

**Physical Plan lÃ :**
- MÃ´ táº£ **"LÃ€M NHÆ¯ THáº¾ NÃ€O"**
- Chá»n thuáº­t toÃ¡n & chiáº¿n lÆ°á»£c thá»±c thi
- CÃ³ Exchange, Join strategy, Aggregate

**VÃ­ dá»¥:**

```code
HashAggregate
Exchange
SortMergeJoin
```

---

## 3ï¸âƒ£ Catalyst Optimizer lÃ m gÃ¬?

**Catalyst:**
- Rewrite Logical Plan
- Push filter xuá»‘ng sá»›m
- Loáº¡i bá» cá»™t dÆ°
- Reorder joins

> ğŸ“Œ Catalyst chá»‰ tá»‘i Æ°u LOGICAL

---

## 4ï¸âƒ£ Adaptive Query Execution (AQE)

***AQE*** **tá»‘i Æ°u PHYSICAL plan táº¡i runtime:**
- Thay Ä‘á»•i join strategy
- Giáº£m shuffle partitions
- Chia skew partition

---

## 5ï¸âƒ£ explain() cÃ³ nhá»¯ng mode nÃ o?

```python
df.explain()                 # Simple
df.explain(True)             # Extended
df.explain("formatted")      # Dá»… Ä‘á»c nháº¥t
```

---

## 6ï¸âƒ£ CÃ¡ch Ä‘á»c explain() nhÆ° kiáº¿n trÃºc sÆ°

**Æ¯u tiÃªn Ä‘á»c theo thá»© tá»±:**

1. CÃ³ Exchange khÃ´ng?
2. Join strategy lÃ  gÃ¬?
3. Aggregate cÃ³ 2 phase khÃ´ng?
4. Sá»‘ partition bao nhiÃªu?
5. CÃ³ Broadcast khÃ´ng?

---

## 7ï¸âƒ£ VÃ­ dá»¥ THá»°C Táº¾

```python
orders.join(customers, "customer_id").explain("formatted")
```

**Káº¿t quáº£:**

```code
== Physical Plan ==
BroadcastHashJoin
:- Scan orders
+- BroadcastExchange
   +- Scan customers
```

**ğŸ‘‰ Káº¿t luáº­n:**

*	CÃ³ shuffle? âŒ
*	CÃ³ broadcast? âœ…
*	Join nhanh

---

# ğŸ§  CÃ‚U Há»I Báº®T BUá»˜C â€“ LEVEL 3 / BÃ€I 2

1.	Logical plan khÃ¡c physical plan á»Ÿ Ä‘iá»ƒm nÃ o?

| Logical Plan | Physical Plan |
|--------------|---------------|
| MÃ´ táº£ *LÃ€M GÃŒ* | MÃ´ táº£ *LÃ€M NHÆ¯ THáº¾ NÃ€O* |
| Äá»™c láº­p thuáº­t toÃ¡n | Gáº¯n vá»›i thuáº­t toÃ¡n thá»±c thi |
| Do Catalyst tá»‘i Æ°u | Do AQE & planner quyáº¿t Ä‘á»‹nh |
| ChÆ°a cÃ³ Exchange | CÃ³ Exchange / Join strategy |

**ğŸ“Œ Key insight:**

>Logical = business logic

>Physical = execution strategy

2.	Catalyst vs AQE khÃ¡c nhau tháº¿ nÃ o?

| Catalyst Optimizer | Adaptive Query Execution (AQE) |
|-------------------|--------------------------------|
| Tá»‘i Æ°u Logical Plan | Äiá»u chá»‰nh Physical Plan |
| TrÆ°á»›c khi job cháº¡y | Trong lÃºc job Ä‘ang cháº¡y |
| Rule-based | Runtime adaptive |
| Pushdown, prune | Change join, split skew |

**ğŸ“Œ Architect mindset:**

>* Catalyst = compile time
>* AQE = runtime intelligence

3.	VÃ¬ sao Exchange xuáº¥t hiá»‡n trong physical plan?

>Exchange xuáº¥t hiá»‡n trong Physical Plan vÃ¬:
>>- Dá»¯ liá»‡u cáº§n Ä‘Æ°á»£c phÃ¢n phá»‘i láº¡i giá»¯a executors
>>- Spark pháº£i Ä‘áº£m báº£o cÃ¡c record cÃ³ cÃ¹ng key náº±m trÃªn cÃ¹ng partition
>>- Exchange chÃ­nh lÃ  biá»ƒu hiá»‡n cá»§a SHUFFLE

**ğŸ“Œ Exchange = Shuffle boundary**

4.	Khi nÃ o Spark chá»n SortMergeJoin?

>Spark chá»n SortMergeJoin khi:
>>- KhÃ´ng thá»ƒ broadcast (dataset lá»›n)
>>- Join key cÃ³ thá»ƒ sort Ä‘Æ°á»£c
>>- spark.sql.join.preferSortMergeJoin = true (default)

ğŸ“Œ SortMergeJoin = **á»•n Ä‘á»‹nh, scalable, nhÆ°ng tá»‘n shuffl**

5.	BroadcastExchange cÃ³ pháº£i shuffle khÃ´ng?

> BroadcastExchange KHÃ”NG pháº£i shuffle vÃ¬:
>>- Dá»¯ liá»‡u nhá» Ä‘Æ°á»£c gá»­i Ä‘áº¿n táº¥t cáº£ executors
>>- KhÃ´ng cÃ³ partition láº¡i dá»¯ liá»‡u lá»›n
>>- KhÃ´ng cÃ³ network shuffle 2 chiá»u

ğŸ“Œ Broadcast = **fan-out**, khÃ´ng pháº£i redistribute

## ğŸ Káº¾T LUáº¬N LEVEL 3 â€“ BÃ€I 2

**ğŸ‘‰ Cáº§n Ä‘Ã£ Ä‘áº¡t má»©c:**

*	Äá»c explain() khÃ´ng sá»£

*	Hiá»ƒu planner Spark Ä‘ang nghÄ© gÃ¬

*	PhÃ¢n biá»‡t Ä‘Æ°á»£c optimization táº§ng nÃ o

---

# ğŸ”¥ LEVEL 3 â€“ BÃ€I 3

## Memory & Executor Model (Ráº¤T QUAN TRá»ŒNG)

---

## 1ï¸âƒ£ Executor lÃ  gÃ¬?

**Executor lÃ :**
- JVM process cháº¡y trÃªn worker node
- Chá»©a CPU cores + memory
- Cháº¡y nhiá»u task song song

ğŸ“Œ 1 executor â‰  1 task

ğŸ“Œ 1 executor = nhiá»u task theo sá»‘ cores

---

## 2ï¸âƒ£ Bá»™ nhá»› Spark Ä‘Æ°á»£c chia tháº¿ nÃ o?

**(Spark â‰¥ 2.x â€“ Unified Memory)**

```text
+----------------------+
|   Executor Memory    |
|----------------------|
| Execution Memory     |  â† shuffle, join, agg
|----------------------|
| Storage Memory       |  â† cache(), persist()
|----------------------|
| User Memory          |
+----------------------+
```

---

## 3ï¸âƒ£ Execution Memory vs Storage Memory

**Execution Memory:**
- DÃ¹ng cho shuffle, join, aggregation
- Quan trá»ng cho performance

**Storage Memory:**
- DÃ¹ng cho cache/persist
- CÃ³ thá»ƒ bá»‹ Ä‘áº©y ra náº¿u execution cáº§n

ğŸ“Œ Execution Æ°u tiÃªn hÆ¡n Storage

---

## 4ï¸âƒ£ VÃ¬ sao cache nhiá»u cÃ³ thá»ƒ lÃ m job cháº­m?

**VÃ¬:**
- Storage chiáº¿m memory
- Execution thiáº¿u memory â†’ spill disk
- Shuffle cháº­m â†’ job cháº­m

> ğŸ‘‰ Cache KHÃ”NG pháº£i lÃºc nÃ o cÅ©ng tá»‘t

---

## 5ï¸âƒ£ Executor memory thá»±c táº¿ KHÃ”NG = spark.executor.memory

Executor memory thá»±c dÃ¹ng =
spark.executor.memory
- memoryOverhead

**ğŸ“Œ memoryOverhead dÃ¹ng cho:**
*	Python
*	JVM overhead
*	Native libs


---

## âš™ï¸ TUNING

### 1ï¸âƒ£ Luáº­t vÃ ng tuning

1. Giáº£m shuffle
2. Kiá»ƒm soÃ¡t partition
3. KhÃ´ng over-cache
4. Executor vá»«a Ä‘á»§, khÃ´ng quÃ¡ to

---

### 2ï¸âƒ£ Nhá»¯ng config Cá»T LÃ•I

```python
spark.conf.set("spark.sql.shuffle.partitions", 200)  # default
spark.conf.set("spark.executor.memory", "4g")
spark.conf.set("spark.executor.cores", 4)
spark.conf.set("spark.sql.adaptive.enabled", "true")
```

---

### 3ï¸âƒ£ Dáº¥u hiá»‡u cáº§n tuning

- Job cháº¡y cháº­m dÃ¹ CPU ráº£nh
- Stage stuck 99%
- Spill to disk nhiá»u
- Má»™t task cháº¡y ráº¥t lÃ¢u

---

### 4ï¸âƒ£ Debug chuáº©n kiáº¿n trÃºc

1. explain()
2. Spark UI â†’ Stage â†’ Task
3. Xem skew
4. Xem spill
5. Äiá»u chá»‰nh partition

---

## ğŸ§  CÃ‚U Há»I Báº®T BUá»˜C â€“ LEVEL 3 / BÃ€I 3

1.	VÃ¬ sao executor quÃ¡ to láº¡i pháº£n tÃ¡c dá»¥ng?
> Executor quÃ¡ to pháº£n tÃ¡c dá»¥ng vÃ¬:
>>- Executor lÃ  1 JVM process â†’ GC pause dÃ i
>>- Nhiá»u cores trong 1 executor â†’ task tranh cháº¥p CPU
>>- Spill lá»›n hÆ¡n khi shuffle
>>- KhÃ³ táº­n dá»¥ng parallelism cá»§a cluster

>**ğŸ“Œ Rule of thumb:**

>>Nhiá»u executor vá»«a pháº£i > Ã­t executor ráº¥t to

2.	Khi nÃ o nÃªn cache, khi nÃ o KHÃ”NG?
>**NÃŠN cache khi:**
>>- Dataset Ä‘Æ°á»£c dÃ¹ng láº¡i nhiá»u láº§n
>>- Dataset nhá» / vá»«a
>>- TrÃ¡nh Ä‘á»c láº¡i tá»« disk / network

>**KHÃ”NG nÃªn cache khi:**
>>- Dataset dÃ¹ng 1 láº§n
>>- Dataset ráº¥t lá»›n
>>- Execution memory Ä‘ang thiáº¿u

>ğŸ“Œ Cache sai â†’ job cháº­m hÆ¡n

3.	Spill to disk xáº£y ra khi nÃ o?
>Spill to disk xáº£y ra khi:
>>- Execution memory khÃ´ng Ä‘á»§
>>- Shuffle / join / aggregation lá»›n
>>- Task giá»¯ quÃ¡ nhiá»u intermediate data

> ğŸ“Œ Spill = **memory pressure**, khÃ´ng chá»‰ do partition

4.	VÃ¬ sao tÄƒng executor memory khÃ´ng luÃ´n giáº£i quyáº¿t cháº­m?
>TÄƒng executor memory khÃ´ng luÃ´n hiá»‡u quáº£ vÃ¬:
>>- Memory tÄƒng â†’ GC lÃ¢u hÆ¡n
>>- Execution/Storage share chung
>>- Bottleneck cÃ³ thá»ƒ lÃ  CPU / shuffle / skew
>>- KhÃ´ng giáº£m sá»‘ Exchange

> ğŸ“Œ Performance â‰  chá»‰ memory

5.	spark.executor.cores nÃªn bao nhiÃªu lÃ  há»£p lÃ½?
> **spark.executor.cores** há»£p lÃ½: **3â€“5** (thÆ°á»ng lÃ  **4**)

>**VÃ¬:**
>>- TrÃ¡nh GC quÃ¡ lá»›n
>>- Tá»‘i Æ°u parallelism
>>- Dá»… scale executor

> ğŸ“Œ 8â€“16 cores/executor = **anti-pattern**

---

## ğŸ Tá»”NG Káº¾T LEVEL 3 â€“ BÃ€I 3

###ğŸ‘‰ Má»¥c tiÃªu:
* Hiá»ƒu executor nhÆ° JVM tháº­t
*	KhÃ´ng cache mÃ¹
*	Biáº¿t spill lÃ  symptom chá»© khÃ´ng pháº£i root cause

### ğŸ”¥ ÄÃ¢y lÃ  tÆ° duy Production-ready

---

# ğŸ”¥ LEVEL 3 â€“ BÃ€I 4

## Spark UI Ä‘á»c trong 5 phÃºt (Cá»°C QUAN TRá»ŒNG)

---

## 1ï¸âƒ£ Spark UI = dashboard debug

Báº¡n cáº§n Ä‘á»c **4 tab chÃ­nh:**

```text
Jobs â†’ Stages â†’ Tasks â†’ Storage
```

---

## 2ï¸âƒ£ Jobs tab â€“ nhÃ¬n gÃ¬?

- Job cháº¡y bao lÃ¢u?
- Job cÃ³ nhiá»u stage khÃ´ng?
- Stage nÃ o chiáº¿m thá»i gian?

> ğŸ“Œ Nhiá»u job = nhiá»u action

---

## 3ï¸âƒ£ Stages tab â€“ QUAN TRá»ŒNG NHáº¤T

- Shuffle Read / Write
- Task time skew
- Stage stuck 99%

### ğŸš¨ Red flag:
-	1 task cháº¡y gáº¥p 10Ã— task khÃ¡c
-	Shuffle Read ráº¥t lá»›n

---

## 4ï¸âƒ£ Tasks tab â€“ báº¯t skew

NhÃ¬n:

- Duration phÃ¢n bá»‘ cÃ³ Ä‘á»u khÃ´ng?
- Task nÃ o cháº­m báº¥t thÆ°á»ng?
- Spill (memory/disk) bao nhiÃªu?

ğŸ“Œ Task cháº­m = key skew / partition skew

---

## 5ï¸âƒ£ Storage tab â€“ cache Ä‘Ãºng hay sai

- Dataset nÃ o Ä‘ang cache?
- Memory usage bao nhiÃªu?
- Cache cÃ³ bá»‹ evict khÃ´ng?

ğŸš¨ Cache nhÆ°ng khÃ´ng reuse = sai

---

## 6ï¸âƒ£ Debug workflow chuáº©n

1. explain()
2. Spark UI â†’ Stage
3. Xem shuffle
4. Xem skew
5. Äiá»u chá»‰nh partition / join

---

## ğŸ§  CÃ‚U Há»I Báº®T BUá»˜C â€“ LEVEL 3 / BÃ€I 4

1.	Khi nÃ o stage stuck 99%?
> Stage stuck 99% khi:
>> - Má»™t hoáº·c vÃ i task cháº¡y ráº¥t lÃ¢u (data skew)
>> - Shuffle read/write lá»›n
>> - Má»™t task giá»¯ pháº§n lá»›n dá»¯ liá»‡u cá»§a stage

> ğŸ“Œ Báº£n cháº¥t: khÃ´ng pháº£i Spark treo â†’ máº¥t cÃ¢n báº±ng task

2.	NhÃ¬n Ä‘Ã¢u Ä‘á»ƒ phÃ¡t hiá»‡n skew?
> PhÃ¡t hiá»‡n skew báº±ng cÃ¡ch:
>> - VÃ o Spark UI â†’ Stages â†’ Tasks
>> - Quan sÃ¡t task duration phÃ¢n bá»‘ khÃ´ng Ä‘á»u
>> - Má»™t task cháº¡y gáº¥p nhiá»u láº§n task khÃ¡c

> ğŸ“Œ Tasks tab > Stages tab

3.	Shuffle Read lá»›n nÃ³i lÃªn Ä‘iá»u gÃ¬?
>Shuffle Read lá»›n cho tháº¥y:
>> - CÃ³ Exchange (data movement)
>> - GroupBy / Join / Repartition
>> - Nguy cÆ¡ skew vÃ  spill

> ğŸ“Œ Shuffle â‰  xáº¥u, shuffle lá»›n + skew má»›i xáº¥u

4.	Cache nhÆ°ng job váº«n cháº­m â†’ vÃ¬ sao?
> Cache nhÆ°ng job váº«n cháº­m vÃ¬:
>>- Dataset khÃ´ng Ä‘Æ°á»£c reuse
>>- Dataset quÃ¡ lá»›n gÃ¢y eviction
>>- Cache chiáº¿m execution memory
>>- Shuffle váº«n xáº£y ra

> ğŸ“Œ Cache khÃ´ng giáº£m shuffle

5.	UI giÃºp quyáº¿t Ä‘á»‹nh tuning nhÆ° tháº¿ nÃ o?
> Spark UI giÃºp quyáº¿t Ä‘á»‹nh:
>>- Repartition / coalesce
>>- Join strategy (broadcast / sort-merge)
>>- Cache hay khÃ´ng cache
>>- Tuning shuffle partitions

> ğŸ“Œ UI = la bÃ n tuning

