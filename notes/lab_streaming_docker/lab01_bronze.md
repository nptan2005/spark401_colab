# üöÄ LAB 01 ‚Äì Kafka ‚Üí Spark Structured Streaming ‚Üí Bronze (MinIO)

---

## üéØ M·ª•c ti√™u
-	Consume Kafka topic orders_raw
-	Parse JSON ‚Üí schema r√µ r√†ng
-	X·ª≠ l√Ω event time + watermark
-	Ghi Bronze layer (Parquet) l√™n MinIO (S3A)
-	C√≥ checkpoint ƒë·ªÉ restart an to√†n
-	S·∫µn s√†ng n·ªëi sang Silver

---

## üß± Ki·∫øn tr√∫c lab

```code
Kafka (orders_raw)
        |
        v
Spark Structured Streaming
        |
        v
MinIO (s3a://lakehouse/bronze/orders/)
        |
   checkpoint (exactly-once)
```

---

## 1Ô∏è‚É£ Schema chu·∫©n (production mindset)

```python
from pyspark.sql.types import *

order_schema = StructType([
    StructField("order_id", StringType()),
    StructField("customer_id", StringType()),
    StructField("merchant_id", StringType()),
    StructField("amount", DoubleType()),
    StructField("event_ts", StringType()),   # parse sau
    StructField("channel", StringType()),
    StructField("country", StringType()),
    StructField("status", StringType())
])
```

---

## 2Ô∏è‚É£ Code LAB ‚Äì Bronze Streaming

#### üìÅ `spark/lab/lab_stream_kafka_to_bronze_orders.py`

```python
from pyspark.sql import SparkSession
from pyspark.sql.functions import *
from pyspark.sql.types import *

spark = (
    SparkSession.builder
    .appName("orders-kafka-bronze")
    .getOrCreate()
)

spark.sparkContext.setLogLevel("WARN")

# ===== Config =====
KAFKA_BOOTSTRAP = "localhost:9094"
TOPIC = "orders_raw"

BRONZE_PATH = "s3a://lakehouse/bronze/orders"
CHECKPOINT_PATH = "s3a://lakehouse/_checkpoints/orders_bronze"

# ===== Schema =====
order_schema = StructType([
    StructField("order_id", StringType()),
    StructField("customer_id", StringType()),
    StructField("merchant_id", StringType()),
    StructField("amount", DoubleType()),
    StructField("event_ts", StringType()),
    StructField("channel", StringType()),
    StructField("country", StringType()),
    StructField("status", StringType())
])

# ===== Read Kafka =====
raw_df = (
    spark.readStream
    .format("kafka")
    .option("kafka.bootstrap.servers", KAFKA_BOOTSTRAP)
    .option("subscribe", TOPIC)
    .option("startingOffsets", "latest")
    .load()
)

# ===== Parse JSON =====
parsed_df = (
    raw_df
    .selectExpr("CAST(value AS STRING) AS json")
    .select(from_json(col("json"), order_schema).alias("data"))
    .select("data.*")
    .withColumn("event_time", to_timestamp("event_ts"))
    .withWatermark("event_time", "10 minutes")
)

# ===== Write Bronze =====
query = (
    parsed_df
    .writeStream
    .format("parquet")
    .outputMode("append")
    .option("path", BRONZE_PATH)
    .option("checkpointLocation", CHECKPOINT_PATH)
    .partitionBy("country", "channel")
    .trigger(processingTime="30 seconds")
    .start()
)

query.awaitTermination()
```

---

## 3Ô∏è‚É£ Ch·∫°y lab (ƒë√∫ng setup c·ªßa b·∫°n)

```bash
scripts/spark_submit.sh \
  spark/lab/lab_stream_kafka_to_bronze_orders.py
```

üëâ KH√îNG c·∫ßn th√™m config g√¨ n·ªØa
(v√¨ `spark_submit.sh` + `S3A` + `Kafka` ƒë√£ OK)

---

## 4Ô∏è‚É£ B·∫Øn data test (Kafka Producer)

B·∫°n ƒë√£ c√≥ script random producer ‚Üí d√πng lu√¥n:

```bash
python spark/test/kafka_producer_orders.py
```

#### Ho·∫∑c ki·ªÉm tra nhanh:

```bash
docker exec -it kafka sh -lc \
  '/opt/kafka/bin/kafka-console-producer.sh \
   --bootstrap-server localhost:9092 \
   --topic orders_raw'
```

Paste:

```code
{"order_id":"o999","customer_id":"c1","merchant_id":"m1","amount":120.5,"event_ts":"2026-01-19T13:30:00","channel":"ECOM","country":"VN","status":"SUCCESS"}
```

---

## 5Ô∏è‚É£ Verify k·∫øt qu·∫£ (Bronze)

#### üîé Ki·ªÉm tra b·∫±ng Spark batch


```bash
scripts/spark_submit.sh - <<EOF
from pyspark.sql import SparkSession
spark = SparkSession.builder.getOrCreate()
df = spark.read.parquet("s3a://lakehouse/bronze/orders")
df.show(5, truncate=False)
print("count =", df.count())
EOF
```

#### üìÇ Tr√™n MinIO UI

```code
lakehouse/
 ‚îî‚îÄ‚îÄ bronze/
     ‚îî‚îÄ‚îÄ orders/
         ‚îú‚îÄ‚îÄ country=VN/
         ‚îÇ   ‚îú‚îÄ‚îÄ channel=ECOM/
         ‚îÇ   ‚îî‚îÄ‚îÄ channel=POS/
```

---

## 6Ô∏è‚É£ V√¨ sao lab n√†y g·∫ßn production

- ‚úî Structured Streaming
- ‚úî Event-time + watermark
- ‚úî Exactly-once (checkpoint)
- ‚úî Partition theo query pattern
- ‚úî Bronze = append-only, raw but typed
- ‚úî D·ªÖ n·ªëi Silver
