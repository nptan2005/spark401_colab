{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4QNLs0qEEWrrdbLz73p9o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nptan2005/spark401_colab/blob/main/notebooks/spark_level_2_join.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y openjdk-17-jdk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "j5Bw8Up4dZaG",
        "outputId": "633c708b-bafc-4abf-ba10-37251bba6bab"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  at-spi2-core fonts-dejavu-core fonts-dejavu-extra gsettings-desktop-schemas\n",
            "  libatk-bridge2.0-0 libatk-wrapper-java libatk-wrapper-java-jni libatk1.0-0\n",
            "  libatk1.0-data libatspi2.0-0 libgail-common libgail18 libgtk2.0-0\n",
            "  libgtk2.0-bin libgtk2.0-common librsvg2-common libxcomposite1 libxt-dev\n",
            "  libxtst6 libxxf86dga1 openjdk-17-jre session-migration x11-utils\n",
            "Suggested packages:\n",
            "  gvfs libxt-doc openjdk-17-demo openjdk-17-source visualvm mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  at-spi2-core fonts-dejavu-core fonts-dejavu-extra gsettings-desktop-schemas\n",
            "  libatk-bridge2.0-0 libatk-wrapper-java libatk-wrapper-java-jni libatk1.0-0\n",
            "  libatk1.0-data libatspi2.0-0 libgail-common libgail18 libgtk2.0-0\n",
            "  libgtk2.0-bin libgtk2.0-common librsvg2-common libxcomposite1 libxt-dev\n",
            "  libxtst6 libxxf86dga1 openjdk-17-jdk openjdk-17-jre session-migration\n",
            "  x11-utils\n",
            "0 upgraded, 24 newly installed, 0 to remove and 1 not upgraded.\n",
            "Need to get 8,212 kB of archives.\n",
            "After this operation, 24.2 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatspi2.0-0 amd64 2.44.0-3 [80.9 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 session-migration amd64 0.3.6 [9,774 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 gsettings-desktop-schemas all 42.0-1ubuntu1 [31.1 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 at-spi2-core amd64 2.44.0-3 [54.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk1.0-data all 2.36.0-3build1 [2,824 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk1.0-0 amd64 2.36.0-3build1 [51.9 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-bridge2.0-0 amd64 2.38.0-3 [66.6 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcomposite1 amd64 1:0.4.5-1build2 [7,192 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java all 0.38.0-5build1 [53.1 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java-jni amd64 0.38.0-5build1 [49.0 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-common all 2.24.33-2ubuntu2.1 [125 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-0 amd64 2.24.33-2ubuntu2.1 [2,038 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail18 amd64 2.24.33-2ubuntu2.1 [15.9 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail-common amd64 2.24.33-2ubuntu2.1 [132 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-bin amd64 2.24.33-2ubuntu2.1 [7,936 B]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 librsvg2-common amd64 2.52.5+dfsg-3ubuntu0.2 [17.7 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jre amd64 17.0.17+10-1~22.04 [238 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jdk amd64 17.0.17+10-1~22.04 [1,521 kB]\n",
            "Fetched 8,212 kB in 0s (20.8 MB/s)\n",
            "Selecting previously unselected package libatspi2.0-0:amd64.\n",
            "(Reading database ... 117528 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libatspi2.0-0_2.44.0-3_amd64.deb ...\n",
            "Unpacking libatspi2.0-0:amd64 (2.44.0-3) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../01-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package session-migration.\n",
            "Preparing to unpack .../02-session-migration_0.3.6_amd64.deb ...\n",
            "Unpacking session-migration (0.3.6) ...\n",
            "Selecting previously unselected package gsettings-desktop-schemas.\n",
            "Preparing to unpack .../03-gsettings-desktop-schemas_42.0-1ubuntu1_all.deb ...\n",
            "Unpacking gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Selecting previously unselected package at-spi2-core.\n",
            "Preparing to unpack .../04-at-spi2-core_2.44.0-3_amd64.deb ...\n",
            "Unpacking at-spi2-core (2.44.0-3) ...\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "Preparing to unpack .../05-fonts-dejavu-core_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-2build1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../06-fonts-dejavu-extra_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-2build1) ...\n",
            "Selecting previously unselected package libatk1.0-data.\n",
            "Preparing to unpack .../07-libatk1.0-data_2.36.0-3build1_all.deb ...\n",
            "Unpacking libatk1.0-data (2.36.0-3build1) ...\n",
            "Selecting previously unselected package libatk1.0-0:amd64.\n",
            "Preparing to unpack .../08-libatk1.0-0_2.36.0-3build1_amd64.deb ...\n",
            "Unpacking libatk1.0-0:amd64 (2.36.0-3build1) ...\n",
            "Selecting previously unselected package libatk-bridge2.0-0:amd64.\n",
            "Preparing to unpack .../09-libatk-bridge2.0-0_2.38.0-3_amd64.deb ...\n",
            "Unpacking libatk-bridge2.0-0:amd64 (2.38.0-3) ...\n",
            "Selecting previously unselected package libxcomposite1:amd64.\n",
            "Preparing to unpack .../10-libxcomposite1_1%3a0.4.5-1build2_amd64.deb ...\n",
            "Unpacking libxcomposite1:amd64 (1:0.4.5-1build2) ...\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "Preparing to unpack .../11-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../12-x11-utils_7.7+5build2_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+5build2) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../13-libatk-wrapper-java_0.38.0-5build1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../14-libatk-wrapper-java-jni_0.38.0-5build1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "Preparing to unpack .../15-libgtk2.0-common_2.24.33-2ubuntu2.1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../16-libgtk2.0-0_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../17-libgail18_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../18-libgail-common_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../19-libgtk2.0-bin_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package librsvg2-common:amd64.\n",
            "Preparing to unpack .../20-librsvg2-common_2.52.5+dfsg-3ubuntu0.2_amd64.deb ...\n",
            "Unpacking librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Selecting previously unselected package libxt-dev:amd64.\n",
            "Preparing to unpack .../21-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n",
            "Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Selecting previously unselected package openjdk-17-jre:amd64.\n",
            "Preparing to unpack .../22-openjdk-17-jre_17.0.17+10-1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-17-jre:amd64 (17.0.17+10-1~22.04) ...\n",
            "Selecting previously unselected package openjdk-17-jdk:amd64.\n",
            "Preparing to unpack .../23-openjdk-17-jdk_17.0.17+10-1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-17-jdk:amd64 (17.0.17+10-1~22.04) ...\n",
            "Setting up session-migration (0.3.6) ...\n",
            "Created symlink /etc/systemd/user/graphical-session-pre.target.wants/session-migration.service ‚Üí /usr/lib/systemd/user/session-migration.service.\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Setting up libatspi2.0-0:amd64 (2.44.0-3) ...\n",
            "Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Setting up fonts-dejavu-core (2.37-2build1) ...\n",
            "Setting up librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Setting up libatk1.0-data (2.36.0-3build1) ...\n",
            "Setting up fonts-dejavu-extra (2.37-2build1) ...\n",
            "Setting up libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libatk1.0-0:amd64 (2.36.0-3build1) ...\n",
            "Setting up libxcomposite1:amd64 (1:0.4.5-1build2) ...\n",
            "Setting up gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Setting up libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libatk-bridge2.0-0:amd64 (2.38.0-3) ...\n",
            "Setting up libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Setting up x11-utils (7.7+5build2) ...\n",
            "Setting up libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Setting up libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up openjdk-17-jre:amd64 (17.0.17+10-1~22.04) ...\n",
            "Setting up openjdk-17-jdk:amd64 (17.0.17+10-1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Processing triggers for libgdk-pixbuf-2.0-0:amd64 (2.42.8+dfsg-1ubuntu0.4) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libglib2.0-0:amd64 (2.72.4-0ubuntu2.6) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.11) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Setting up at-spi2-core (2.44.0-3) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://archive.apache.org/dist/spark/spark-4.0.1/spark-4.0.1-bin-hadoop3.tgz\n",
        "!tar xf spark-4.0.1-bin-hadoop3.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8j0_ek35dz3K",
        "outputId": "92d1e51f-4d07-4b41-a302-2748ec7a7640"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-29 09:36:23--  https://archive.apache.org/dist/spark/spark-4.0.1/spark-4.0.1-bin-hadoop3.tgz\n",
            "Resolving archive.apache.org (archive.apache.org)... 65.108.204.189, 2a01:4f9:1a:a084::2\n",
            "Connecting to archive.apache.org (archive.apache.org)|65.108.204.189|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 548955321 (524M) [application/x-gzip]\n",
            "Saving to: ‚Äòspark-4.0.1-bin-hadoop3.tgz‚Äô\n",
            "\n",
            "spark-4.0.1-bin-had 100%[===================>] 523.52M  10.5MB/s    in 32s     \n",
            "\n",
            "2025-12-29 09:36:55 (16.3 MB/s) - ‚Äòspark-4.0.1-bin-hadoop3.tgz‚Äô saved [548955321/548955321]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hx3iurVwdRe8",
        "outputId": "64869af9-a5b1-4e42-fdcb-6c9e35a31176"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark version: 4.0.1\n"
          ]
        }
      ],
      "source": [
        "# ===============================\n",
        "# Spark 4.0.1 Setup (REQUIRED)\n",
        "# ===============================\n",
        "import os\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-17-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-4.0.1-bin-hadoop3\"\n",
        "os.environ[\"PATH\"] += \":/content/spark-4.0.1-bin-hadoop3/bin\"\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Spark401-Training\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"4\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(\"Spark version:\", spark.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ Spark Level 2 ‚Äì B√†i 2: Filter, Select, WithColumn & Execution Plan\n",
        "\n",
        "## üéØ M·ª•c ti√™u b√†i n√†y\n",
        "\n",
        "**Sau b√†i n√†y b·∫°n s·∫Ω:**\n",
        ">*\tHi·ªÉu Transformation vs Action\n",
        ">*\tBi·∫øt Spark c√≥ ch·∫°y ngay hay kh√¥ng\n",
        ">*\tB·∫Øt ƒë·∫ßu ch·∫°m v√†o shuffle (r·∫•t quan tr·ªçng)\n",
        "\n",
        "---\n",
        "\n",
        "## üß™ B√†i to√°n\n",
        "\n",
        "**D·ªØ li·ªáu giao d·ªãch:**\n",
        "\n",
        "|order_id|customer_id|amount|country|\n",
        "|--------|-----------|------|-------|\n",
        "|1|C001|120|VN|\n",
        "|2|C002|80|VN|\n",
        "|3|C003|200|SG|\n",
        "|4|C001|50|VN|\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XKd5fDAgeRWA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìå B∆∞·ªõc 1 ‚Äì T·∫°o DataFrame:"
      ],
      "metadata": {
        "id": "MjX4Tjn0fKgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "data = [\n",
        "    (1, \"C001\", 120, \"VN\"),\n",
        "    (2, \"C002\", 80, \"VN\"),\n",
        "    (3, \"C003\", 200, \"SG\"),\n",
        "    (4, \"C001\", 50, \"VN\"),\n",
        "]\n",
        "\n",
        "columns = [\"order_id\", \"customer_id\", \"amount\", \"country\"]\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEyL-zDceSXQ",
        "outputId": "7e0f0cb9-87e4-4613-9a88-b82cf7a3e927"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------+------+-------+\n",
            "|order_id|customer_id|amount|country|\n",
            "+--------+-----------+------+-------+\n",
            "|       1|       C001|   120|     VN|\n",
            "|       2|       C002|    80|     VN|\n",
            "|       3|       C003|   200|     SG|\n",
            "|       4|       C001|    50|     VN|\n",
            "+--------+-----------+------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìå B∆∞·ªõc 2 ‚Äì Transformation (KH√îNG ch·∫°y ngay)\n",
        "\n",
        "```python\n",
        "df_vn = df.filter(df.country == \"VN\")\n",
        "df_vn_high = df_vn.filter(df_vn.amount > 100)\n",
        "```\n",
        "\n",
        ">‚ùì Spark ƒë√£ ch·∫°y ch∆∞a?\n",
        "\n",
        ">üëâ CH∆ØA\n"
      ],
      "metadata": {
        "id": "83d9ow6gfzaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_vn = df.filter(df.country == \"VN\")\n",
        "df_vn_high = df_vn.filter(df_vn.amount > 100)"
      ],
      "metadata": {
        "id": "s9kVMccJf-em"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìå B∆∞·ªõc 3 ‚Äì Action (Spark b·∫Øt ƒë·∫ßu ch·∫°y)\n",
        "\n",
        "```python\n",
        "df_vn_high.show()\n",
        "```\n",
        "\n",
        "#### üß† Nguy√™n l√Ω quan tr·ªçng\n",
        "\n",
        "|Lo·∫°i|V√≠ d·ª•|\n",
        "|----|-----|\n",
        "|Transformation|filter, select, withColumn|\n",
        "|Action|show, count, collect|\n",
        "\n",
        "> üëâ Spark lazy execution\n"
      ],
      "metadata": {
        "id": "SdSDAFg1gFMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_vn_high.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B78wWbIdgeDA",
        "outputId": "75a7dc13-1aa2-40ab-8449-0a12c790df8e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------+------+-------+\n",
            "|order_id|customer_id|amount|country|\n",
            "+--------+-----------+------+-------+\n",
            "|       1|       C001|   120|     VN|\n",
            "+--------+-----------+------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìå B∆∞·ªõc 4 ‚Äì Th√™m c·ªôt m·ªõi"
      ],
      "metadata": {
        "id": "OxfeUzL2giom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.withColumn(\n",
        "    \"amount_category\",\n",
        "    F.when(df.amount >= 100, \"HIGH\").otherwise(\"LOW\")\n",
        ")\n",
        "\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnImyu4Hgxb5",
        "outputId": "05306d4e-2794-43f1-cc92-aaff8676ff99"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------+------+-------+---------------+\n",
            "|order_id|customer_id|amount|country|amount_category|\n",
            "+--------+-----------+------+-------+---------------+\n",
            "|       1|       C001|   120|     VN|           HIGH|\n",
            "|       2|       C002|    80|     VN|            LOW|\n",
            "|       3|       C003|   200|     SG|           HIGH|\n",
            "|       4|       C001|    50|     VN|            LOW|\n",
            "+--------+-----------+------+-------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìå B∆∞·ªõc 5 ‚Äì Xem Execution Plan:\n",
        "\n",
        "```python\n",
        "df2.explain(True)\n",
        "```\n",
        "\n",
        "Result:\n",
        "\n",
        "```code\n",
        "== Physical Plan ==\n",
        "*(1) Project\n",
        "+- *(1) Scan ExistingRDD\n",
        "```\n",
        "\n",
        "> üëâ Ch∆∞a c√≥ shuffle ‚Üí nh·∫π"
      ],
      "metadata": {
        "id": "juP4wBo4g6hd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-EYB5b6hPe2",
        "outputId": "041ae566-1107-42bd-d600-2c6f228a03db"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Project [unresolvedstarwithcolumns(amount_category, CASE WHEN '`>=`(amount#2L, 100) THEN HIGH ELSE LOW END, None)]\n",
            "+- LogicalRDD [order_id#0L, customer_id#1, amount#2L, country#3], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "order_id: bigint, customer_id: string, amount: bigint, country: string, amount_category: string\n",
            "Project [order_id#0L, customer_id#1, amount#2L, country#3, CASE WHEN (amount#2L >= cast(100 as bigint)) THEN HIGH ELSE LOW END AS amount_category#30]\n",
            "+- LogicalRDD [order_id#0L, customer_id#1, amount#2L, country#3], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Project [order_id#0L, customer_id#1, amount#2L, country#3, CASE WHEN (amount#2L >= 100) THEN HIGH ELSE LOW END AS amount_category#30]\n",
            "+- LogicalRDD [order_id#0L, customer_id#1, amount#2L, country#3], false\n",
            "\n",
            "== Physical Plan ==\n",
            "*(1) Project [order_id#0L, customer_id#1, amount#2L, country#3, CASE WHEN (amount#2L >= 100) THEN HIGH ELSE LOW END AS amount_category#30]\n",
            "+- *(1) Scan ExistingRDD[order_id#0L,customer_id#1,amount#2L,country#3]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ Spark Level 2 ‚Äì B√†i 3: groupBy, agg & SHUFFLE (c·ªët l√µi Spark)\n",
        "\n",
        "> **ƒê√¢y l√† b√†i QUAN TR·ªåNG NH·∫§T tr∆∞·ªõc khi b·∫°n l√†m Spark th·∫≠t s·ª± trong CDP / Dataproc / EMR**\n",
        "\n",
        "\n",
        "## üéØ M·ª•c ti√™u b√†i n√†y\n",
        "\n",
        "**Sau b√†i n√†y b·∫°n s·∫Ω:**\n",
        ">*\tHi·ªÉu shuffle l√† g√¨ (ƒë√∫ng b·∫£n ch·∫•t)\n",
        ">*\tBi·∫øt v√¨ sao groupBy r·∫•t ƒë·∫Øt\n",
        ">*\tƒê·ªçc ƒë∆∞·ª£c execution plan c√≥ shuffle\n",
        ">*\tBi·∫øt khi n√†o Spark scale / khi n√†o ch·∫øt"
      ],
      "metadata": {
        "id": "R_a_Yguqi4cY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1Ô∏è‚É£ B√†i to√°n\n",
        "\n",
        "D·ªØ li·ªáu order (nh∆∞ tr∆∞·ªõc):"
      ],
      "metadata": {
        "id": "kilyEjRSjXMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "data = [\n",
        "    (1, \"C001\", 120, \"VN\"),\n",
        "    (2, \"C002\", 80, \"VN\"),\n",
        "    (3, \"C003\", 200, \"SG\"),\n",
        "    (4, \"C001\", 50, \"VN\"),\n",
        "    (5, \"C002\", 70, \"SG\"),\n",
        "]\n",
        "\n",
        "columns = [\"order_id\", \"customer_id\", \"amount\", \"country\"]\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MhjgobKjcuw",
        "outputId": "bdc5df25-675a-4e67-bd18-55ea004bb5a7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------+------+-------+\n",
            "|order_id|customer_id|amount|country|\n",
            "+--------+-----------+------+-------+\n",
            "|       1|       C001|   120|     VN|\n",
            "|       2|       C002|    80|     VN|\n",
            "|       3|       C003|   200|     SG|\n",
            "|       4|       C001|    50|     VN|\n",
            "|       5|       C002|    70|     SG|\n",
            "+--------+-----------+------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2Ô∏è‚É£ GroupBy c∆° b·∫£n\n",
        "\n",
        "‚ùì Y√™u c·∫ßu\n",
        "\n",
        "üëâ T·ªïng ti·ªÅn theo customer_id"
      ],
      "metadata": {
        "id": "YQX77vQNjnwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_group = df.groupBy(\"customer_id\").agg(\n",
        "    F.sum(\"amount\").alias(\"total_amount\")\n",
        ")\n",
        "\n",
        "df_group.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmrMq4nqjs9e",
        "outputId": "6732e92f-92dd-47b7-dcec-f851fe17f333"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------+\n",
            "|customer_id|total_amount|\n",
            "+-----------+------------+\n",
            "|       C001|         170|\n",
            "|       C002|         150|\n",
            "|       C003|         200|\n",
            "+-----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üî• STOP ‚Äì ƒê√¢y l√† l√∫c SHUFFLE x·∫£y ra\n",
        "\n",
        "## 3Ô∏è‚É£ Shuffle l√† g√¨? (Hi·ªÉu ƒë√∫ng, kh√¥ng m∆° h·ªì)\n",
        "\n",
        "### üß† ƒê·ªãnh nghƒ©a CHU·∫®N:\n",
        "\n",
        "**Shuffle** = **Spark** ph·∫£i di chuy·ªÉn d·ªØ li·ªáu gi·ªØa c√°c executor ƒë·ªÉ gom c√°c key gi·ªëng nhau v·ªÅ c√πng 1 n∆°i\n",
        "\n",
        "**V√≠ d·ª•:**\n",
        ">*\tOrder c·ªßa C001 n·∫±m ·ªü partition 1\n",
        ">*\tOrder kh√°c c·ªßa C001 n·∫±m ·ªü partition 5\n",
        ">> ‚Üí Spark b·∫Øt bu·ªôc ph·∫£i chuy·ªÉn d·ªØ li·ªáu\n",
        "\n",
        ">üëâ Network + Disk + Serialize = t·ªën t√†i nguy√™n\n",
        "\n",
        "### üß© Minh h·ªça logic\n",
        "\n",
        "```code\n",
        "Partition 1: C001, C002\n",
        "Partition 2: C003\n",
        "Partition 3: C001, C002\n",
        "\n",
        "groupBy(customer_id)\n",
        "        ‚Üì\n",
        "Shuffle\n",
        "        ‚Üì\n",
        "Partition A: C001\n",
        "Partition B: C002\n",
        "Partition C: C003\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "EeKPcDSrj6Qp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4Ô∏è‚É£ Xem Execution Plan (B·∫ÆT BU·ªòC)\n",
        "\n",
        "B·∫°n s·∫Ω th·∫•y ƒëo·∫°n gi·ªëng:\n",
        "\n",
        "```code\n",
        "Exchange hashpartitioning(customer_id, 200)\n",
        "```\n",
        "\n",
        "üìå Exchange = SHUFFLE"
      ],
      "metadata": {
        "id": "k79LbXxsko2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_group.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmT1PsG9kqb4",
        "outputId": "52e6f64f-28d4-443c-f175-c05b8c7fbb15"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Aggregate ['customer_id], ['customer_id, 'sum('amount) AS total_amount#64]\n",
            "+- LogicalRDD [order_id#47L, customer_id#48, amount#49L, country#50], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "customer_id: string, total_amount: bigint\n",
            "Aggregate [customer_id#48], [customer_id#48, sum(amount#49L) AS total_amount#64L]\n",
            "+- LogicalRDD [order_id#47L, customer_id#48, amount#49L, country#50], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Aggregate [customer_id#48], [customer_id#48, sum(amount#49L) AS total_amount#64L]\n",
            "+- Project [customer_id#48, amount#49L]\n",
            "   +- LogicalRDD [order_id#47L, customer_id#48, amount#49L, country#50], false\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- HashAggregate(keys=[customer_id#48], functions=[sum(amount#49L)], output=[customer_id#48, total_amount#64L])\n",
            "   +- Exchange hashpartitioning(customer_id#48, 4), ENSURE_REQUIREMENTS, [plan_id=119]\n",
            "      +- HashAggregate(keys=[customer_id#48], functions=[partial_sum(amount#49L)], output=[customer_id#48, sum#73L])\n",
            "         +- Project [customer_id#48, amount#49L]\n",
            "            +- Scan ExistingRDD[order_id#47L,customer_id#48,amount#49L,country#50]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5Ô∏è‚É£ V√¨ sao shuffle NGUY HI·ªÇM?\n",
        "\n",
        "|V·∫•n ƒë·ªÅ|H·∫≠u qu·∫£|\n",
        "|------|-------|\n",
        "|Nhi·ªÅu d·ªØ li·ªáu|Ch·∫≠m|\n",
        "|Skew key|Executor ch·∫øt|\n",
        "|Network y·∫øu|Timeout|\n",
        "|Disk ch·∫≠m|Spill|\n",
        "\n",
        "> üëâ 90% job Spark ch·∫≠m = shuffle k√©m ki·ªÉm so√°t\n"
      ],
      "metadata": {
        "id": "J6L38dz8lA55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6Ô∏è‚É£ V√≠ d·ª• SHUFFLE T·ªÜ (anti-pattern)\n",
        "\n",
        "```python\n",
        "df.groupBy(\"country\", \"customer_id\").count().show()\n",
        "```\n",
        "\n",
        ">‚ùå GroupBy nhi·ªÅu c·ªôt kh√¥ng c·∫ßn thi·∫øt\n",
        "\n",
        ">‚ùå Cardinality cao ‚Üí shuffle n·∫∑ng\n"
      ],
      "metadata": {
        "id": "F5MKXwlclzOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"country\", \"customer_id\").count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mwc9VfS_l4DE",
        "outputId": "cadfb3b7-de3b-4797-cf0d-ef635ccbadfe"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+-----+\n",
            "|country|customer_id|count|\n",
            "+-------+-----------+-----+\n",
            "|     VN|       C001|    2|\n",
            "|     VN|       C002|    1|\n",
            "|     SG|       C002|    1|\n",
            "|     SG|       C003|    1|\n",
            "+-------+-----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7Ô∏è‚É£ Gi·∫£m shuffle ‚Äì c√°ch ƒë·∫ßu ti√™n (c∆° b·∫£n)\n",
        "\n",
        "### ‚úÖ Ch·ªâ groupBy ƒë√∫ng th·ª© c·∫ßn\n",
        "\n",
        "```python\n",
        "df.groupBy(\"country\").sum(\"amount\").show()\n",
        "```"
      ],
      "metadata": {
        "id": "fcoa0T_VmFOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"country\").sum(\"amount\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65qVKb6mmMMj",
        "outputId": "1c681d2a-5e88-4ded-f26e-71ed038e7303"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+\n",
            "|country|sum(amount)|\n",
            "+-------+-----------+\n",
            "|     VN|        250|\n",
            "|     SG|        270|\n",
            "+-------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8Ô∏è‚É£ Ki·ªÉm so√°t s·ªë partition khi shuffle"
      ],
      "metadata": {
        "id": "Sb4dRS9LmQwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# M·∫∑c ƒë·ªãnh:\n",
        "\n",
        "spark.conf.get(\"spark.sql.shuffle.partitions\")\n",
        "\n",
        "# ‚Üí th∆∞·ªùng l√† 200 (QU√Å NHI·ªÄU cho dataset nh·ªè)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "L_OLay-cmTCa",
        "outputId": "0c2da4df-0606-4a96-cc49-d0c26f703e08"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üîß Gi·∫£m xu·ªëng khi test / small data\n",
        "\n",
        "spark.conf.set(\"spark.sql.shuffle.partitions\", \"4\")\n",
        "\n",
        "# üëâ Ch·∫°y l·∫°i groupBy v√† explain"
      ],
      "metadata": {
        "id": "T8J7ycTEmjKT"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}