{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nptan2005/spark401_colab/blob/main/notebooks/spark_level_3_join.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymoS2-DnPyPK"
      },
      "source": [
        "# install java"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FXRB533HPuRz",
        "outputId": "46bf1c28-2623-4ab3-9b38-543d32951e87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  at-spi2-core fonts-dejavu-core fonts-dejavu-extra gsettings-desktop-schemas\n",
            "  libatk-bridge2.0-0 libatk-wrapper-java libatk-wrapper-java-jni libatk1.0-0\n",
            "  libatk1.0-data libatspi2.0-0 libgail-common libgail18 libgtk2.0-0\n",
            "  libgtk2.0-bin libgtk2.0-common librsvg2-common libxcomposite1 libxt-dev\n",
            "  libxtst6 libxxf86dga1 openjdk-17-jre session-migration x11-utils\n",
            "Suggested packages:\n",
            "  gvfs libxt-doc openjdk-17-demo openjdk-17-source visualvm mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  at-spi2-core fonts-dejavu-core fonts-dejavu-extra gsettings-desktop-schemas\n",
            "  libatk-bridge2.0-0 libatk-wrapper-java libatk-wrapper-java-jni libatk1.0-0\n",
            "  libatk1.0-data libatspi2.0-0 libgail-common libgail18 libgtk2.0-0\n",
            "  libgtk2.0-bin libgtk2.0-common librsvg2-common libxcomposite1 libxt-dev\n",
            "  libxtst6 libxxf86dga1 openjdk-17-jdk openjdk-17-jre session-migration\n",
            "  x11-utils\n",
            "0 upgraded, 24 newly installed, 0 to remove and 1 not upgraded.\n",
            "Need to get 8,212 kB of archives.\n",
            "After this operation, 24.2 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatspi2.0-0 amd64 2.44.0-3 [80.9 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 session-migration amd64 0.3.6 [9,774 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 gsettings-desktop-schemas all 42.0-1ubuntu1 [31.1 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 at-spi2-core amd64 2.44.0-3 [54.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk1.0-data all 2.36.0-3build1 [2,824 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk1.0-0 amd64 2.36.0-3build1 [51.9 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-bridge2.0-0 amd64 2.38.0-3 [66.6 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcomposite1 amd64 1:0.4.5-1build2 [7,192 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java all 0.38.0-5build1 [53.1 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java-jni amd64 0.38.0-5build1 [49.0 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-common all 2.24.33-2ubuntu2.1 [125 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-0 amd64 2.24.33-2ubuntu2.1 [2,038 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail18 amd64 2.24.33-2ubuntu2.1 [15.9 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail-common amd64 2.24.33-2ubuntu2.1 [132 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-bin amd64 2.24.33-2ubuntu2.1 [7,936 B]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 librsvg2-common amd64 2.52.5+dfsg-3ubuntu0.2 [17.7 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jre amd64 17.0.17+10-1~22.04 [238 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jdk amd64 17.0.17+10-1~22.04 [1,521 kB]\n",
            "Fetched 8,212 kB in 1s (8,928 kB/s)\n",
            "Selecting previously unselected package libatspi2.0-0:amd64.\n",
            "(Reading database ... 117528 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libatspi2.0-0_2.44.0-3_amd64.deb ...\n",
            "Unpacking libatspi2.0-0:amd64 (2.44.0-3) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../01-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package session-migration.\n",
            "Preparing to unpack .../02-session-migration_0.3.6_amd64.deb ...\n",
            "Unpacking session-migration (0.3.6) ...\n",
            "Selecting previously unselected package gsettings-desktop-schemas.\n",
            "Preparing to unpack .../03-gsettings-desktop-schemas_42.0-1ubuntu1_all.deb ...\n",
            "Unpacking gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Selecting previously unselected package at-spi2-core.\n",
            "Preparing to unpack .../04-at-spi2-core_2.44.0-3_amd64.deb ...\n",
            "Unpacking at-spi2-core (2.44.0-3) ...\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "Preparing to unpack .../05-fonts-dejavu-core_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-2build1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../06-fonts-dejavu-extra_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-2build1) ...\n",
            "Selecting previously unselected package libatk1.0-data.\n",
            "Preparing to unpack .../07-libatk1.0-data_2.36.0-3build1_all.deb ...\n",
            "Unpacking libatk1.0-data (2.36.0-3build1) ...\n",
            "Selecting previously unselected package libatk1.0-0:amd64.\n",
            "Preparing to unpack .../08-libatk1.0-0_2.36.0-3build1_amd64.deb ...\n",
            "Unpacking libatk1.0-0:amd64 (2.36.0-3build1) ...\n",
            "Selecting previously unselected package libatk-bridge2.0-0:amd64.\n",
            "Preparing to unpack .../09-libatk-bridge2.0-0_2.38.0-3_amd64.deb ...\n",
            "Unpacking libatk-bridge2.0-0:amd64 (2.38.0-3) ...\n",
            "Selecting previously unselected package libxcomposite1:amd64.\n",
            "Preparing to unpack .../10-libxcomposite1_1%3a0.4.5-1build2_amd64.deb ...\n",
            "Unpacking libxcomposite1:amd64 (1:0.4.5-1build2) ...\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "Preparing to unpack .../11-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../12-x11-utils_7.7+5build2_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+5build2) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../13-libatk-wrapper-java_0.38.0-5build1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../14-libatk-wrapper-java-jni_0.38.0-5build1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "Preparing to unpack .../15-libgtk2.0-common_2.24.33-2ubuntu2.1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../16-libgtk2.0-0_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../17-libgail18_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../18-libgail-common_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../19-libgtk2.0-bin_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package librsvg2-common:amd64.\n",
            "Preparing to unpack .../20-librsvg2-common_2.52.5+dfsg-3ubuntu0.2_amd64.deb ...\n",
            "Unpacking librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Selecting previously unselected package libxt-dev:amd64.\n",
            "Preparing to unpack .../21-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n",
            "Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Selecting previously unselected package openjdk-17-jre:amd64.\n",
            "Preparing to unpack .../22-openjdk-17-jre_17.0.17+10-1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-17-jre:amd64 (17.0.17+10-1~22.04) ...\n",
            "Selecting previously unselected package openjdk-17-jdk:amd64.\n",
            "Preparing to unpack .../23-openjdk-17-jdk_17.0.17+10-1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-17-jdk:amd64 (17.0.17+10-1~22.04) ...\n",
            "Setting up session-migration (0.3.6) ...\n",
            "Created symlink /etc/systemd/user/graphical-session-pre.target.wants/session-migration.service â†’ /usr/lib/systemd/user/session-migration.service.\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Setting up libatspi2.0-0:amd64 (2.44.0-3) ...\n",
            "Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Setting up fonts-dejavu-core (2.37-2build1) ...\n",
            "Setting up librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Setting up libatk1.0-data (2.36.0-3build1) ...\n",
            "Setting up fonts-dejavu-extra (2.37-2build1) ...\n",
            "Setting up libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libatk1.0-0:amd64 (2.36.0-3build1) ...\n",
            "Setting up libxcomposite1:amd64 (1:0.4.5-1build2) ...\n",
            "Setting up gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Setting up libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libatk-bridge2.0-0:amd64 (2.38.0-3) ...\n",
            "Setting up libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Setting up x11-utils (7.7+5build2) ...\n",
            "Setting up libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Setting up libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up openjdk-17-jre:amd64 (17.0.17+10-1~22.04) ...\n",
            "Setting up openjdk-17-jdk:amd64 (17.0.17+10-1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Processing triggers for libgdk-pixbuf-2.0-0:amd64 (2.42.8+dfsg-1ubuntu0.4) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libglib2.0-0:amd64 (2.72.4-0ubuntu2.6) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.11) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Setting up at-spi2-core (2.44.0-3) ...\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y openjdk-17-jdk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8tiwcqXQBy4"
      },
      "source": [
        "# Install Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh9es2efQFis",
        "outputId": "a495dc23-d19a-4ebb-c873-5cb88caab413"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-12-30 07:54:41--  https://archive.apache.org/dist/spark/spark-4.0.1/spark-4.0.1-bin-hadoop3.tgz\n",
            "Resolving archive.apache.org (archive.apache.org)... 65.108.204.189, 2a01:4f9:1a:a084::2\n",
            "Connecting to archive.apache.org (archive.apache.org)|65.108.204.189|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 548955321 (524M) [application/x-gzip]\n",
            "Saving to: â€˜spark-4.0.1-bin-hadoop3.tgzâ€™\n",
            "\n",
            "spark-4.0.1-bin-had 100%[===================>] 523.52M  15.7MB/s    in 36s     \n",
            "\n",
            "2025-12-30 07:55:18 (14.4 MB/s) - â€˜spark-4.0.1-bin-hadoop3.tgzâ€™ saved [548955321/548955321]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://archive.apache.org/dist/spark/spark-4.0.1/spark-4.0.1-bin-hadoop3.tgz\n",
        "!tar xf spark-4.0.1-bin-hadoop3.tgz"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup environment"
      ],
      "metadata": {
        "id": "XrwzJiEpRD2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Spark 4.0.1 Setup (REQUIRED)\n",
        "# ===============================\n",
        "import os\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-17-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-4.0.1-bin-hadoop3\"\n",
        "os.environ[\"PATH\"] += \":/content/spark-4.0.1-bin-hadoop3/bin\"\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Spark401-Training\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"4\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(\"Spark version:\", spark.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onDP5Vk9RGX7",
        "outputId": "3b2bcfc9-d388-42d0-a68e-e39222d4af84"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark version: 4.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸš€ Spark Level 3 â€“ Internals\n",
        "\n",
        "## BÃ i 1: DAG â€“ Stage â€“ Task (Cá»T LÃ•I Cá»¦A SPARK)\n",
        "\n",
        "â— Náº¿u hiá»ƒu pháº§n nÃ y â†’ báº¡n vÆ°á»£t 90% ngÆ°á»i dÃ¹ng Spark\n",
        "\n",
        "---\n",
        "\n",
        "### 1ï¸âƒ£ Tá»•ng quan kiáº¿n trÃºc thá»±c thi Spark\n",
        "\n",
        "**Spark Execution Flow:**\n",
        "\n",
        "```code\n",
        "Code\n",
        " â†“\n",
        "Logical Plan\n",
        " â†“\n",
        "Physical Plan\n",
        " â†“\n",
        "DAG\n",
        " â†“\n",
        "Stages\n",
        " â†“\n",
        "Tasks\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 2ï¸âƒ£ DAG lÃ  gÃ¬?\n",
        "\n",
        "**DAG (Directed Acyclic Graph) lÃ :**\n",
        "- Äá»“ thá»‹ biá»ƒu diá»…n toÃ n bá»™ pipeline tÃ­nh toÃ¡n\n",
        "- CÃ¡c node = transformation\n",
        "- CÃ¡c cáº¡nh = dependency\n",
        "- KhÃ´ng cÃ³ vÃ²ng láº·p\n",
        "\n",
        "> ðŸ“Œ DAG Ä‘Æ°á»£c táº¡o KHI CÃ“ ACTION\n",
        "\n",
        "---\n",
        "\n",
        "### 3ï¸âƒ£ Stage lÃ  gÃ¬?\n",
        "\n",
        "**Stage lÃ :**\n",
        "- Má»™t táº­p cÃ¡c task cÃ³ thá»ƒ cháº¡y song song\n",
        "- Bá»‹ chia cáº¯t bá»Ÿi SHUFFLE\n",
        "\n",
        "**Quy táº¯c VÃ€NG:**\n",
        "\n",
        "> Má»—i láº§n shuffle â†’ táº¡o stage má»›i\n",
        "\n",
        "** VÃ­ dá»¥:**\n",
        "\n",
        "```python\n",
        "df.filter(...).select(...)   # Stage 1\n",
        "df.groupBy(...).count()      # Stage 2 (shuffle)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 4ï¸âƒ£ Task lÃ  gÃ¬?\n",
        "\n",
        "**Task lÃ :**\n",
        "- ÄÆ¡n vá»‹ nhá» nháº¥t Spark cÃ³ thá»ƒ thá»±c thi\n",
        "- Má»™t task xá»­ lÃ½ má»™t partition\n",
        "- Cháº¡y trÃªn má»™t executor\n",
        "\n",
        "> ðŸ“Œ Sá»‘ task = sá»‘ partition trong stage\n",
        "\n",
        "---\n",
        "\n",
        "### 5ï¸âƒ£ VÃ­ dá»¥ THá»°C Táº¾\n",
        "\n",
        "```python\n",
        "df = spark.read.parquet(\"data\")\n",
        "\n",
        "df2 = df.filter(\"amount > 1000\")      # Transformation\n",
        "df3 = df2.groupBy(\"customer_id\").sum(\"amount\")  # Shuffle\n",
        "\n",
        "df3.show()   # Action\n",
        "```\n",
        "\n",
        "#### DAG sáº½ lÃ :\n",
        "\n",
        "**Stage 0:**\n",
        "- Read\n",
        "- Filter\n",
        "\n",
        "**Stage 1:**\n",
        "- Exchange (shuffle)\n",
        "- HashAggregate\n",
        "\n",
        "---\n",
        "\n",
        "### 6ï¸âƒ£ VÃ¬ sao hiá»ƒu Stage quan trá»ng?\n",
        "\n",
        "|**Váº¥n Ä‘á»**|**LiÃªn quan**|\n",
        "|----------|-------------|\n",
        "|Job cháº¡y cháº­m|Stage skew|\n",
        "|Executor OOM|Task quÃ¡ lá»›n|\n",
        "|Shuffle nhiá»u|Stage split|\n",
        "|Tuning Spark|Stage-based|\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  CÃ‚U Há»ŽI Báº®T BUá»˜C â€“ LEVEL 3 / BÃ€I 1\n",
        "\n",
        "1. Khi nÃ o DAG Ä‘Æ°á»£c táº¡o?\n",
        "> DAG Ä‘Æ°á»£c táº¡o khi Spark gáº·p má»™t ACTION\n",
        ">>(vÃ­ dá»¥: show(), collect(), count(), write). TrÆ°á»›c Ä‘Ã³, Spark chá»‰ xÃ¢y dá»±ng Logical Plan vÃ  chÆ°a thá»±c thi báº¥t ká»³ phÃ©p tÃ­nh nÃ o.\n",
        "2. Äiá»u gÃ¬ quyáº¿t Ä‘á»‹nh sá»‘ stage?\n",
        "> Sá»‘ stage Ä‘Æ°á»£c quyáº¿t Ä‘á»‹nh bá»Ÿi sá»‘ láº§n shuffle.\n",
        ">>Má»—i phÃ©p toÃ¡n gÃ¢y shuffle (Exchange) sáº½ táº¡o ra má»™t stage má»›i.\n",
        "\n",
        "> ðŸ“Œ Tá»« khÃ³a chuáº©n: Stage boundary = Shuffle boundary\n",
        "3. Sá»‘ task phá»¥ thuá»™c vÃ o yáº¿u tá»‘ nÃ o?\n",
        "> Sá»‘ task trong má»™t stage báº±ng sá»‘ partition cá»§a dá»¯ liá»‡u trong stage Ä‘Ã³.\n",
        ">> Má»—i task xá»­ lÃ½ Ä‘Ãºng 1 partition.\n",
        "4. VÃ¬ sao Spark khÃ´ng thá»ƒ chia nhá» má»™t task Ä‘ang cháº¡y?\n",
        "> Spark khÃ´ng thá»ƒ chia nhá» má»™t task Ä‘ang cháº¡y vÃ¬:\n",
        ">>- Task lÃ  Ä‘Æ¡n vá»‹ thá»±c thi nhá» nháº¥t cá»§a Spark\n",
        ">>- Task Ä‘Ã£ Ä‘Æ°á»£c gÃ¡n cho má»™t executor\n",
        ">>- Spark khÃ´ng cÃ³ cÆ¡ cháº¿ preempt hoáº·c split task\n",
        ">>>â†’ Náº¿u task bá»‹ skew, toÃ n bá»™ stage pháº£i chá»\n",
        "\n",
        "> ðŸ“Œ Tá»« khÃ³a chuáº©n: Straggler task\n",
        "5. VÃ¬ sao giáº£m shuffle giÃºp Spark nhanh hÆ¡n?\n",
        "> Giáº£m shuffle giÃºp Spark nhanh hÆ¡n vÃ¬:\n",
        ">>- Shuffle gÃ¢y I/O lá»›n (disk + network)\n",
        ">>- Shuffle táº¡o thÃªm stage (barrier)\n",
        ">>- Shuffle táº¡o nhiá»u task nhá», tá»‘n overhead\n",
        ">>- Shuffle dá»… gÃ¢y skew vÃ  OOM\n",
        "\n",
        ">ðŸ“Œ Shuffle lÃ  káº» thÃ¹ sá»‘ 1 cá»§a hiá»‡u nÄƒng Spark\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ Tá»”NG Káº¾T LEVEL 3 â€“ BÃ€I 1\n",
        "\n",
        "ðŸ‘‰ Báº¡n Ä‘Ã£ náº¯m Cá»T LÃ•I **internals Spark**\n",
        "\n",
        "ðŸ‘‰ Chá»‰ cáº§n nhá»›:\n",
        "\n",
        "* DAG â†’ Stage â†’ Task\n",
        "*\tShuffle = Stage boundary\n",
        "*\tTask = Ä‘Æ¡n vá»‹ khÃ´ng chia nhá»"
      ],
      "metadata": {
        "id": "8YGiy45lRN2-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ”¥ LEVEL 3 â€“ BÃ€I 2\n",
        "\n",
        "## Logical Plan vs Physical Plan\n",
        "\n",
        "### â— ÄÃ¢y lÃ  pháº§n giÃºp báº¡n Ä‘á»c explain() nhÆ° senior / architect\n",
        "\n",
        "---\n",
        "\n",
        "## 1ï¸âƒ£ Logical Plan lÃ  gÃ¬?\n",
        "\n",
        "**Logical Plan lÃ :**\n",
        "- MÃ´ táº£ **\"LÃ€M GÃŒ\"**\n",
        "- Äá»™c láº­p vá»›i cÃ¡ch thá»±c thi\n",
        "- ÄÆ°á»£c xÃ¢y tá»« DataFrame / SQL\n",
        "\n",
        "**VÃ­ dá»¥:**\n",
        "\n",
        "```python\n",
        "df.filter(\"amount > 1000\").groupBy(\"country\").sum()\n",
        "```\n",
        "\n",
        "**ðŸ‘‰ Logical plan chá»‰ nÃ³i:**\n",
        "\n",
        ">Lá»c â†’ Group â†’ Sum\n",
        "\n",
        "---\n",
        "\n",
        "## 2ï¸âƒ£ Physical Plan lÃ  gÃ¬?\n",
        "\n",
        "**Physical Plan lÃ :**\n",
        "- MÃ´ táº£ **\"LÃ€M NHÆ¯ THáº¾ NÃ€O\"**\n",
        "- Chá»n thuáº­t toÃ¡n & chiáº¿n lÆ°á»£c thá»±c thi\n",
        "- CÃ³ Exchange, Join strategy, Aggregate\n",
        "\n",
        "**VÃ­ dá»¥:**\n",
        "\n",
        "```code\n",
        "HashAggregate\n",
        "Exchange\n",
        "SortMergeJoin\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 3ï¸âƒ£ Catalyst Optimizer lÃ m gÃ¬?\n",
        "\n",
        "**Catalyst:**\n",
        "- Rewrite Logical Plan\n",
        "- Push filter xuá»‘ng sá»›m\n",
        "- Loáº¡i bá» cá»™t dÆ°\n",
        "- Reorder joins\n",
        "\n",
        "> ðŸ“Œ Catalyst chá»‰ tá»‘i Æ°u LOGICAL\n",
        "\n",
        "---\n",
        "\n",
        "## 4ï¸âƒ£ Adaptive Query Execution (AQE)\n",
        "\n",
        "***AQE*** **tá»‘i Æ°u PHYSICAL plan táº¡i runtime:**\n",
        "- Thay Ä‘á»•i join strategy\n",
        "- Giáº£m shuffle partitions\n",
        "- Chia skew partition\n",
        "\n",
        "---\n",
        "\n",
        "## 5ï¸âƒ£ explain() cÃ³ nhá»¯ng mode nÃ o?\n",
        "\n",
        "```python\n",
        "df.explain()                 # Simple\n",
        "df.explain(True)             # Extended\n",
        "df.explain(\"formatted\")      # Dá»… Ä‘á»c nháº¥t\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 6ï¸âƒ£ CÃ¡ch Ä‘á»c explain() nhÆ° kiáº¿n trÃºc sÆ°\n",
        "\n",
        "**Æ¯u tiÃªn Ä‘á»c theo thá»© tá»±:**\n",
        "\n",
        "1. CÃ³ Exchange khÃ´ng?\n",
        "2. Join strategy lÃ  gÃ¬?\n",
        "3. Aggregate cÃ³ 2 phase khÃ´ng?\n",
        "4. Sá»‘ partition bao nhiÃªu?\n",
        "5. CÃ³ Broadcast khÃ´ng?\n",
        "\n",
        "---\n",
        "\n",
        "## 7ï¸âƒ£ VÃ­ dá»¥ THá»°C Táº¾\n",
        "\n",
        "```python\n",
        "orders.join(customers, \"customer_id\").explain(\"formatted\")\n",
        "```\n",
        "\n",
        "**Káº¿t quáº£:**\n",
        "\n",
        "```code\n",
        "== Physical Plan ==\n",
        "BroadcastHashJoin\n",
        ":- Scan orders\n",
        "+- BroadcastExchange\n",
        "   +- Scan customers\n",
        "```\n",
        "\n",
        "**ðŸ‘‰ Káº¿t luáº­n:**\n",
        "\n",
        "*\tCÃ³ shuffle? âŒ\n",
        "*\tCÃ³ broadcast? âœ…\n",
        "*\tJoin nhanh\n",
        "\n",
        "---\n",
        "\n",
        "# ðŸ§  CÃ‚U Há»ŽI Báº®T BUá»˜C â€“ LEVEL 3 / BÃ€I 2\n",
        "\n",
        "1.\tLogical plan khÃ¡c physical plan á»Ÿ Ä‘iá»ƒm nÃ o?\n",
        "\n",
        "| Logical Plan | Physical Plan |\n",
        "|--------------|---------------|\n",
        "| MÃ´ táº£ *LÃ€M GÃŒ* | MÃ´ táº£ *LÃ€M NHÆ¯ THáº¾ NÃ€O* |\n",
        "| Äá»™c láº­p thuáº­t toÃ¡n | Gáº¯n vá»›i thuáº­t toÃ¡n thá»±c thi |\n",
        "| Do Catalyst tá»‘i Æ°u | Do AQE & planner quyáº¿t Ä‘á»‹nh |\n",
        "| ChÆ°a cÃ³ Exchange | CÃ³ Exchange / Join strategy |\n",
        "\n",
        "**ðŸ“Œ Key insight:**\n",
        "\n",
        ">Logical = business logic\n",
        "\n",
        ">Physical = execution strategy\n",
        "\n",
        "2.\tCatalyst vs AQE khÃ¡c nhau tháº¿ nÃ o?\n",
        "\n",
        "| Catalyst Optimizer | Adaptive Query Execution (AQE) |\n",
        "|-------------------|--------------------------------|\n",
        "| Tá»‘i Æ°u Logical Plan | Äiá»u chá»‰nh Physical Plan |\n",
        "| TrÆ°á»›c khi job cháº¡y | Trong lÃºc job Ä‘ang cháº¡y |\n",
        "| Rule-based | Runtime adaptive |\n",
        "| Pushdown, prune | Change join, split skew |\n",
        "\n",
        "**ðŸ“Œ Architect mindset:**\n",
        "\n",
        ">* Catalyst = compile time\n",
        ">* AQE = runtime intelligence\n",
        "\n",
        "3.\tVÃ¬ sao Exchange xuáº¥t hiá»‡n trong physical plan?\n",
        "\n",
        ">Exchange xuáº¥t hiá»‡n trong Physical Plan vÃ¬:\n",
        ">>- Dá»¯ liá»‡u cáº§n Ä‘Æ°á»£c phÃ¢n phá»‘i láº¡i giá»¯a executors\n",
        ">>- Spark pháº£i Ä‘áº£m báº£o cÃ¡c record cÃ³ cÃ¹ng key náº±m trÃªn cÃ¹ng partition\n",
        ">>- Exchange chÃ­nh lÃ  biá»ƒu hiá»‡n cá»§a SHUFFLE\n",
        "\n",
        "**ðŸ“Œ Exchange = Shuffle boundary**\n",
        "\n",
        "4.\tKhi nÃ o Spark chá»n SortMergeJoin?\n",
        "\n",
        ">Spark chá»n SortMergeJoin khi:\n",
        ">>- KhÃ´ng thá»ƒ broadcast (dataset lá»›n)\n",
        ">>- Join key cÃ³ thá»ƒ sort Ä‘Æ°á»£c\n",
        ">>- spark.sql.join.preferSortMergeJoin = true (default)\n",
        "\n",
        "ðŸ“Œ SortMergeJoin = **á»•n Ä‘á»‹nh, scalable, nhÆ°ng tá»‘n shuffl**\n",
        "\n",
        "5.\tBroadcastExchange cÃ³ pháº£i shuffle khÃ´ng?\n",
        "\n",
        "> BroadcastExchange KHÃ”NG pháº£i shuffle vÃ¬:\n",
        ">>- Dá»¯ liá»‡u nhá» Ä‘Æ°á»£c gá»­i Ä‘áº¿n táº¥t cáº£ executors\n",
        ">>- KhÃ´ng cÃ³ partition láº¡i dá»¯ liá»‡u lá»›n\n",
        ">>- KhÃ´ng cÃ³ network shuffle 2 chiá»u\n",
        "\n",
        "ðŸ“Œ Broadcast = **fan-out**, khÃ´ng pháº£i redistribute\n",
        "\n",
        "## ðŸ Káº¾T LUáº¬N LEVEL 3 â€“ BÃ€I 2\n",
        "\n",
        "**ðŸ‘‰ Cáº§n Ä‘Ã£ Ä‘áº¡t má»©c:**\n",
        "\n",
        "*\tÄá»c explain() khÃ´ng sá»£\n",
        "\n",
        "*\tHiá»ƒu planner Spark Ä‘ang nghÄ© gÃ¬\n",
        "\n",
        "*\tPhÃ¢n biá»‡t Ä‘Æ°á»£c optimization táº§ng nÃ o"
      ],
      "metadata": {
        "id": "nWta99uoZkCa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ”¥ LEVEL 3 â€“ BÃ€I 3\n",
        "\n",
        "## Memory & Executor Model (Ráº¤T QUAN TRá»ŒNG)\n",
        "\n",
        "---\n",
        "\n",
        "## 1ï¸âƒ£ Executor lÃ  gÃ¬?\n",
        "\n",
        "**Executor lÃ :**\n",
        "- JVM process cháº¡y trÃªn worker node\n",
        "- Chá»©a CPU cores + memory\n",
        "- Cháº¡y nhiá»u task song song\n",
        "\n",
        "ðŸ“Œ 1 executor â‰  1 task\n",
        "\n",
        "ðŸ“Œ 1 executor = nhiá»u task theo sá»‘ cores\n",
        "\n",
        "---\n",
        "\n",
        "## 2ï¸âƒ£ Bá»™ nhá»› Spark Ä‘Æ°á»£c chia tháº¿ nÃ o?\n",
        "\n",
        "**(Spark â‰¥ 2.x â€“ Unified Memory)**\n",
        "\n",
        "```text\n",
        "+----------------------+\n",
        "|   Executor Memory    |\n",
        "|----------------------|\n",
        "| Execution Memory     |  â† shuffle, join, agg\n",
        "|----------------------|\n",
        "| Storage Memory       |  â† cache(), persist()\n",
        "|----------------------|\n",
        "| User Memory          |\n",
        "+----------------------+\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 3ï¸âƒ£ Execution Memory vs Storage Memory\n",
        "\n",
        "**Execution Memory:**\n",
        "- DÃ¹ng cho shuffle, join, aggregation\n",
        "- Quan trá»ng cho performance\n",
        "\n",
        "**Storage Memory:**\n",
        "- DÃ¹ng cho cache/persist\n",
        "- CÃ³ thá»ƒ bá»‹ Ä‘áº©y ra náº¿u execution cáº§n\n",
        "\n",
        "ðŸ“Œ Execution Æ°u tiÃªn hÆ¡n Storage\n",
        "\n",
        "---\n",
        "\n",
        "## 4ï¸âƒ£ VÃ¬ sao cache nhiá»u cÃ³ thá»ƒ lÃ m job cháº­m?\n",
        "\n",
        "**VÃ¬:**\n",
        "- Storage chiáº¿m memory\n",
        "- Execution thiáº¿u memory â†’ spill disk\n",
        "- Shuffle cháº­m â†’ job cháº­m\n",
        "\n",
        "> ðŸ‘‰ Cache KHÃ”NG pháº£i lÃºc nÃ o cÅ©ng tá»‘t\n",
        "\n",
        "---\n",
        "\n",
        "## 5ï¸âƒ£ Executor memory thá»±c táº¿ KHÃ”NG = spark.executor.memory\n",
        "\n",
        "Executor memory thá»±c dÃ¹ng =\n",
        "spark.executor.memory\n",
        "- memoryOverhead\n",
        "\n",
        "**ðŸ“Œ memoryOverhead dÃ¹ng cho:**\n",
        "*\tPython\n",
        "*\tJVM overhead\n",
        "*\tNative libs\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## âš™ï¸ TUNING\n",
        "\n",
        "### 1ï¸âƒ£ Luáº­t vÃ ng tuning\n",
        "\n",
        "1. Giáº£m shuffle\n",
        "2. Kiá»ƒm soÃ¡t partition\n",
        "3. KhÃ´ng over-cache\n",
        "4. Executor vá»«a Ä‘á»§, khÃ´ng quÃ¡ to\n",
        "\n",
        "---\n",
        "\n",
        "### 2ï¸âƒ£ Nhá»¯ng config Cá»T LÃ•I\n",
        "\n",
        "```python\n",
        "spark.conf.set(\"spark.sql.shuffle.partitions\", 200)  # default\n",
        "spark.conf.set(\"spark.executor.memory\", \"4g\")\n",
        "spark.conf.set(\"spark.executor.cores\", 4)\n",
        "spark.conf.set(\"spark.sql.adaptive.enabled\", \"true\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 3ï¸âƒ£ Dáº¥u hiá»‡u cáº§n tuning\n",
        "\n",
        "- Job cháº¡y cháº­m dÃ¹ CPU ráº£nh\n",
        "- Stage stuck 99%\n",
        "- Spill to disk nhiá»u\n",
        "- Má»™t task cháº¡y ráº¥t lÃ¢u\n",
        "\n",
        "---\n",
        "\n",
        "### 4ï¸âƒ£ Debug chuáº©n kiáº¿n trÃºc\n",
        "\n",
        "1. explain()\n",
        "2. Spark UI â†’ Stage â†’ Task\n",
        "3. Xem skew\n",
        "4. Xem spill\n",
        "5. Äiá»u chá»‰nh partition\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  CÃ‚U Há»ŽI Báº®T BUá»˜C â€“ LEVEL 3 / BÃ€I 3\n",
        "\n",
        "1.\tVÃ¬ sao executor quÃ¡ to láº¡i pháº£n tÃ¡c dá»¥ng?\n",
        "> Executor quÃ¡ to pháº£n tÃ¡c dá»¥ng vÃ¬:\n",
        ">>- Executor lÃ  1 JVM process â†’ GC pause dÃ i\n",
        ">>- Nhiá»u cores trong 1 executor â†’ task tranh cháº¥p CPU\n",
        ">>- Spill lá»›n hÆ¡n khi shuffle\n",
        ">>- KhÃ³ táº­n dá»¥ng parallelism cá»§a cluster\n",
        "\n",
        ">**ðŸ“Œ Rule of thumb:**\n",
        "\n",
        ">>Nhiá»u executor vá»«a pháº£i > Ã­t executor ráº¥t to\n",
        "\n",
        "2.\tKhi nÃ o nÃªn cache, khi nÃ o KHÃ”NG?\n",
        ">**NÃŠN cache khi:**\n",
        ">>- Dataset Ä‘Æ°á»£c dÃ¹ng láº¡i nhiá»u láº§n\n",
        ">>- Dataset nhá» / vá»«a\n",
        ">>- TrÃ¡nh Ä‘á»c láº¡i tá»« disk / network\n",
        "\n",
        ">**KHÃ”NG nÃªn cache khi:**\n",
        ">>- Dataset dÃ¹ng 1 láº§n\n",
        ">>- Dataset ráº¥t lá»›n\n",
        ">>- Execution memory Ä‘ang thiáº¿u\n",
        "\n",
        ">ðŸ“Œ Cache sai â†’ job cháº­m hÆ¡n\n",
        "\n",
        "3.\tSpill to disk xáº£y ra khi nÃ o?\n",
        ">Spill to disk xáº£y ra khi:\n",
        ">>- Execution memory khÃ´ng Ä‘á»§\n",
        ">>- Shuffle / join / aggregation lá»›n\n",
        ">>- Task giá»¯ quÃ¡ nhiá»u intermediate data\n",
        "\n",
        "> ðŸ“Œ Spill = **memory pressure**, khÃ´ng chá»‰ do partition\n",
        "\n",
        "4.\tVÃ¬ sao tÄƒng executor memory khÃ´ng luÃ´n giáº£i quyáº¿t cháº­m?\n",
        ">TÄƒng executor memory khÃ´ng luÃ´n hiá»‡u quáº£ vÃ¬:\n",
        ">>- Memory tÄƒng â†’ GC lÃ¢u hÆ¡n\n",
        ">>- Execution/Storage share chung\n",
        ">>- Bottleneck cÃ³ thá»ƒ lÃ  CPU / shuffle / skew\n",
        ">>- KhÃ´ng giáº£m sá»‘ Exchange\n",
        "\n",
        "> ðŸ“Œ Performance â‰  chá»‰ memory\n",
        "\n",
        "5.\tspark.executor.cores nÃªn bao nhiÃªu lÃ  há»£p lÃ½?\n",
        "> **spark.executor.cores** há»£p lÃ½: **3â€“5** (thÆ°á»ng lÃ  **4**)\n",
        "\n",
        ">**VÃ¬:**\n",
        ">>- TrÃ¡nh GC quÃ¡ lá»›n\n",
        ">>- Tá»‘i Æ°u parallelism\n",
        ">>- Dá»… scale executor\n",
        "\n",
        "> ðŸ“Œ 8â€“16 cores/executor = **anti-pattern**\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ Tá»”NG Káº¾T LEVEL 3 â€“ BÃ€I 3\n",
        "\n",
        "###ðŸ‘‰ Má»¥c tiÃªu:\n",
        "* Hiá»ƒu executor nhÆ° JVM tháº­t\n",
        "*\tKhÃ´ng cache mÃ¹\n",
        "*\tBiáº¿t spill lÃ  symptom chá»© khÃ´ng pháº£i root cause\n",
        "\n",
        "### ðŸ”¥ ÄÃ¢y lÃ  tÆ° duy Production-ready\n",
        "\n"
      ],
      "metadata": {
        "id": "POl9pt_xgF6y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ”¥ LEVEL 3 â€“ BÃ€I 4\n",
        "\n",
        "## Spark UI Ä‘á»c trong 5 phÃºt (Cá»°C QUAN TRá»ŒNG)\n",
        "\n",
        "---\n",
        "\n",
        "## 1ï¸âƒ£ Spark UI = dashboard debug\n",
        "\n",
        "Báº¡n cáº§n Ä‘á»c **4 tab chÃ­nh:**\n",
        "\n",
        "```text\n",
        "Jobs â†’ Stages â†’ Tasks â†’ Storage\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 2ï¸âƒ£ Jobs tab â€“ nhÃ¬n gÃ¬?\n",
        "\n",
        "- Job cháº¡y bao lÃ¢u?\n",
        "- Job cÃ³ nhiá»u stage khÃ´ng?\n",
        "- Stage nÃ o chiáº¿m thá»i gian?\n",
        "\n",
        "> ðŸ“Œ Nhiá»u job = nhiá»u action\n",
        "\n",
        "---\n",
        "\n",
        "## 3ï¸âƒ£ Stages tab â€“ QUAN TRá»ŒNG NHáº¤T\n",
        "\n",
        "- Shuffle Read / Write\n",
        "- Task time skew\n",
        "- Stage stuck 99%\n",
        "\n",
        "### ðŸš¨ Red flag:\n",
        "-\t1 task cháº¡y gáº¥p 10Ã— task khÃ¡c\n",
        "-\tShuffle Read ráº¥t lá»›n\n",
        "\n",
        "---\n",
        "\n",
        "## 4ï¸âƒ£ Tasks tab â€“ báº¯t skew\n",
        "\n",
        "NhÃ¬n:\n",
        "\n",
        "- Duration phÃ¢n bá»‘ cÃ³ Ä‘á»u khÃ´ng?\n",
        "- Task nÃ o cháº­m báº¥t thÆ°á»ng?\n",
        "- Spill (memory/disk) bao nhiÃªu?\n",
        "\n",
        "ðŸ“Œ Task cháº­m = key skew / partition skew\n",
        "\n",
        "---\n",
        "\n",
        "## 5ï¸âƒ£ Storage tab â€“ cache Ä‘Ãºng hay sai\n",
        "\n",
        "- Dataset nÃ o Ä‘ang cache?\n",
        "- Memory usage bao nhiÃªu?\n",
        "- Cache cÃ³ bá»‹ evict khÃ´ng?\n",
        "\n",
        "ðŸš¨ Cache nhÆ°ng khÃ´ng reuse = sai\n",
        "\n",
        "---\n",
        "\n",
        "## 6ï¸âƒ£ Debug workflow chuáº©n\n",
        "\n",
        "1. explain()\n",
        "2. Spark UI â†’ Stage\n",
        "3. Xem shuffle\n",
        "4. Xem skew\n",
        "5. Äiá»u chá»‰nh partition / join\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  CÃ‚U Há»ŽI Báº®T BUá»˜C â€“ LEVEL 3 / BÃ€I 4\n",
        "\n",
        "1.\tKhi nÃ o stage stuck 99%?\n",
        "> Stage stuck 99% khi:\n",
        ">> - Má»™t hoáº·c vÃ i task cháº¡y ráº¥t lÃ¢u (data skew)\n",
        ">> - Shuffle read/write lá»›n\n",
        ">> - Má»™t task giá»¯ pháº§n lá»›n dá»¯ liá»‡u cá»§a stage\n",
        "\n",
        "> ðŸ“Œ Báº£n cháº¥t: khÃ´ng pháº£i Spark treo â†’ máº¥t cÃ¢n báº±ng task\n",
        "\n",
        "2.\tNhÃ¬n Ä‘Ã¢u Ä‘á»ƒ phÃ¡t hiá»‡n skew?\n",
        "> PhÃ¡t hiá»‡n skew báº±ng cÃ¡ch:\n",
        ">> - VÃ o Spark UI â†’ Stages â†’ Tasks\n",
        ">> - Quan sÃ¡t task duration phÃ¢n bá»‘ khÃ´ng Ä‘á»u\n",
        ">> - Má»™t task cháº¡y gáº¥p nhiá»u láº§n task khÃ¡c\n",
        "\n",
        "> ðŸ“Œ Tasks tab > Stages tab\n",
        "\n",
        "3.\tShuffle Read lá»›n nÃ³i lÃªn Ä‘iá»u gÃ¬?\n",
        ">Shuffle Read lá»›n cho tháº¥y:\n",
        ">> - CÃ³ Exchange (data movement)\n",
        ">> - GroupBy / Join / Repartition\n",
        ">> - Nguy cÆ¡ skew vÃ  spill\n",
        "\n",
        "> ðŸ“Œ Shuffle â‰  xáº¥u, shuffle lá»›n + skew má»›i xáº¥u\n",
        "\n",
        "4.\tCache nhÆ°ng job váº«n cháº­m â†’ vÃ¬ sao?\n",
        "> Cache nhÆ°ng job váº«n cháº­m vÃ¬:\n",
        ">>- Dataset khÃ´ng Ä‘Æ°á»£c reuse\n",
        ">>- Dataset quÃ¡ lá»›n gÃ¢y eviction\n",
        ">>- Cache chiáº¿m execution memory\n",
        ">>- Shuffle váº«n xáº£y ra\n",
        "\n",
        "> ðŸ“Œ Cache khÃ´ng giáº£m shuffle\n",
        "\n",
        "5.\tUI giÃºp quyáº¿t Ä‘á»‹nh tuning nhÆ° tháº¿ nÃ o?\n",
        "> Spark UI giÃºp quyáº¿t Ä‘á»‹nh:\n",
        ">>- Repartition / coalesce\n",
        ">>- Join strategy (broadcast / sort-merge)\n",
        ">>- Cache hay khÃ´ng cache\n",
        ">>- Tuning shuffle partitions\n",
        "\n",
        "> ðŸ“Œ UI = la bÃ n tuning\n"
      ],
      "metadata": {
        "id": "v-Ug-6b4nIbU"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMm8MoxV5pnOPhJ7e3e3Xvi",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}