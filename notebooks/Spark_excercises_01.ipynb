{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN45KpRjz6MpPNEcMuDzVcU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nptan2005/spark401_colab/blob/main/notebooks/Spark_excercises_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WC1ds5G3FALw",
        "outputId": "e0d4e10b-5959-4a46-f4ad-f7e36a877ddd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  at-spi2-core fonts-dejavu-core fonts-dejavu-extra gsettings-desktop-schemas\n",
            "  libatk-bridge2.0-0 libatk-wrapper-java libatk-wrapper-java-jni libatk1.0-0\n",
            "  libatk1.0-data libatspi2.0-0 libgail-common libgail18 libgtk2.0-0\n",
            "  libgtk2.0-bin libgtk2.0-common librsvg2-common libxcomposite1 libxt-dev\n",
            "  libxtst6 libxxf86dga1 openjdk-17-jre session-migration x11-utils\n",
            "Suggested packages:\n",
            "  gvfs libxt-doc openjdk-17-demo openjdk-17-source visualvm mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  at-spi2-core fonts-dejavu-core fonts-dejavu-extra gsettings-desktop-schemas\n",
            "  libatk-bridge2.0-0 libatk-wrapper-java libatk-wrapper-java-jni libatk1.0-0\n",
            "  libatk1.0-data libatspi2.0-0 libgail-common libgail18 libgtk2.0-0\n",
            "  libgtk2.0-bin libgtk2.0-common librsvg2-common libxcomposite1 libxt-dev\n",
            "  libxtst6 libxxf86dga1 openjdk-17-jdk openjdk-17-jre session-migration\n",
            "  x11-utils\n",
            "0 upgraded, 24 newly installed, 0 to remove and 1 not upgraded.\n",
            "Need to get 8,212 kB of archives.\n",
            "After this operation, 24.2 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatspi2.0-0 amd64 2.44.0-3 [80.9 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 session-migration amd64 0.3.6 [9,774 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 gsettings-desktop-schemas all 42.0-1ubuntu1 [31.1 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 at-spi2-core amd64 2.44.0-3 [54.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk1.0-data all 2.36.0-3build1 [2,824 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk1.0-0 amd64 2.36.0-3build1 [51.9 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-bridge2.0-0 amd64 2.38.0-3 [66.6 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcomposite1 amd64 1:0.4.5-1build2 [7,192 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java all 0.38.0-5build1 [53.1 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java-jni amd64 0.38.0-5build1 [49.0 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-common all 2.24.33-2ubuntu2.1 [125 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-0 amd64 2.24.33-2ubuntu2.1 [2,038 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail18 amd64 2.24.33-2ubuntu2.1 [15.9 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail-common amd64 2.24.33-2ubuntu2.1 [132 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-bin amd64 2.24.33-2ubuntu2.1 [7,936 B]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 librsvg2-common amd64 2.52.5+dfsg-3ubuntu0.2 [17.7 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jre amd64 17.0.17+10-1~22.04 [238 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jdk amd64 17.0.17+10-1~22.04 [1,521 kB]\n",
            "Fetched 8,212 kB in 0s (19.1 MB/s)\n",
            "Selecting previously unselected package libatspi2.0-0:amd64.\n",
            "(Reading database ... 117528 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libatspi2.0-0_2.44.0-3_amd64.deb ...\n",
            "Unpacking libatspi2.0-0:amd64 (2.44.0-3) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../01-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package session-migration.\n",
            "Preparing to unpack .../02-session-migration_0.3.6_amd64.deb ...\n",
            "Unpacking session-migration (0.3.6) ...\n",
            "Selecting previously unselected package gsettings-desktop-schemas.\n",
            "Preparing to unpack .../03-gsettings-desktop-schemas_42.0-1ubuntu1_all.deb ...\n",
            "Unpacking gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Selecting previously unselected package at-spi2-core.\n",
            "Preparing to unpack .../04-at-spi2-core_2.44.0-3_amd64.deb ...\n",
            "Unpacking at-spi2-core (2.44.0-3) ...\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "Preparing to unpack .../05-fonts-dejavu-core_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-2build1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../06-fonts-dejavu-extra_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-2build1) ...\n",
            "Selecting previously unselected package libatk1.0-data.\n",
            "Preparing to unpack .../07-libatk1.0-data_2.36.0-3build1_all.deb ...\n",
            "Unpacking libatk1.0-data (2.36.0-3build1) ...\n",
            "Selecting previously unselected package libatk1.0-0:amd64.\n",
            "Preparing to unpack .../08-libatk1.0-0_2.36.0-3build1_amd64.deb ...\n",
            "Unpacking libatk1.0-0:amd64 (2.36.0-3build1) ...\n",
            "Selecting previously unselected package libatk-bridge2.0-0:amd64.\n",
            "Preparing to unpack .../09-libatk-bridge2.0-0_2.38.0-3_amd64.deb ...\n",
            "Unpacking libatk-bridge2.0-0:amd64 (2.38.0-3) ...\n",
            "Selecting previously unselected package libxcomposite1:amd64.\n",
            "Preparing to unpack .../10-libxcomposite1_1%3a0.4.5-1build2_amd64.deb ...\n",
            "Unpacking libxcomposite1:amd64 (1:0.4.5-1build2) ...\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "Preparing to unpack .../11-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../12-x11-utils_7.7+5build2_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+5build2) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../13-libatk-wrapper-java_0.38.0-5build1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../14-libatk-wrapper-java-jni_0.38.0-5build1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "Preparing to unpack .../15-libgtk2.0-common_2.24.33-2ubuntu2.1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../16-libgtk2.0-0_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../17-libgail18_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../18-libgail-common_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../19-libgtk2.0-bin_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package librsvg2-common:amd64.\n",
            "Preparing to unpack .../20-librsvg2-common_2.52.5+dfsg-3ubuntu0.2_amd64.deb ...\n",
            "Unpacking librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Selecting previously unselected package libxt-dev:amd64.\n",
            "Preparing to unpack .../21-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n",
            "Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Selecting previously unselected package openjdk-17-jre:amd64.\n",
            "Preparing to unpack .../22-openjdk-17-jre_17.0.17+10-1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-17-jre:amd64 (17.0.17+10-1~22.04) ...\n",
            "Selecting previously unselected package openjdk-17-jdk:amd64.\n",
            "Preparing to unpack .../23-openjdk-17-jdk_17.0.17+10-1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-17-jdk:amd64 (17.0.17+10-1~22.04) ...\n",
            "Setting up session-migration (0.3.6) ...\n",
            "Created symlink /etc/systemd/user/graphical-session-pre.target.wants/session-migration.service → /usr/lib/systemd/user/session-migration.service.\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Setting up libatspi2.0-0:amd64 (2.44.0-3) ...\n",
            "Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Setting up fonts-dejavu-core (2.37-2build1) ...\n",
            "Setting up librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Setting up libatk1.0-data (2.36.0-3build1) ...\n",
            "Setting up fonts-dejavu-extra (2.37-2build1) ...\n",
            "Setting up libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libatk1.0-0:amd64 (2.36.0-3build1) ...\n",
            "Setting up libxcomposite1:amd64 (1:0.4.5-1build2) ...\n",
            "Setting up gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Setting up libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libatk-bridge2.0-0:amd64 (2.38.0-3) ...\n",
            "Setting up libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Setting up x11-utils (7.7+5build2) ...\n",
            "Setting up libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Setting up libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up openjdk-17-jre:amd64 (17.0.17+10-1~22.04) ...\n",
            "Setting up openjdk-17-jdk:amd64 (17.0.17+10-1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Processing triggers for libgdk-pixbuf-2.0-0:amd64 (2.42.8+dfsg-1ubuntu0.4) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libglib2.0-0:amd64 (2.72.4-0ubuntu2.6) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.11) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Setting up at-spi2-core (2.44.0-3) ...\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y openjdk-17-jdk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://archive.apache.org/dist/spark/spark-4.0.1/spark-4.0.1-bin-hadoop3.tgz\n",
        "!tar xf spark-4.0.1-bin-hadoop3.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "x9ZzvEniFkH-",
        "outputId": "104f8835-9d65-4a79-d04a-3389bc18cb0b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-05 06:38:42--  https://archive.apache.org/dist/spark/spark-4.0.1/spark-4.0.1-bin-hadoop3.tgz\n",
            "Resolving archive.apache.org (archive.apache.org)... 65.108.204.189, 2a01:4f9:1a:a084::2\n",
            "Connecting to archive.apache.org (archive.apache.org)|65.108.204.189|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 548955321 (524M) [application/x-gzip]\n",
            "Saving to: ‘spark-4.0.1-bin-hadoop3.tgz’\n",
            "\n",
            "spark-4.0.1-bin-had 100%[===================>] 523.52M  9.20MB/s    in 67s     \n",
            "\n",
            "2026-01-05 06:39:50 (7.82 MB/s) - ‘spark-4.0.1-bin-hadoop3.tgz’ saved [548955321/548955321]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Spark 4.0.1 Setup (REQUIRED)\n",
        "# ===============================\n",
        "import os\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-17-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-4.0.1-bin-hadoop3\"\n",
        "os.environ[\"PATH\"] += \":/content/spark-4.0.1-bin-hadoop3/bin\"\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Spark401-Training\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"4\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(\"Spark version:\", spark.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HI6xpzwzFx4L",
        "outputId": "fa07e7f6-73cd-4927-885f-9b0cee70dba2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark version: 4.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Tạo dữ liệu giả lập (có skew)\n",
        "\n",
        "## 1.1 Helper timing + imports"
      ],
      "metadata": {
        "id": "r-Ig97RcI7l6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time, random\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql import types as T\n",
        "\n",
        "def timed(label, fn):\n",
        "    t0 = time.time()\n",
        "    out = fn()\n",
        "    t1 = time.time()\n",
        "    print(f\"[{label}] took {t1 - t0:.2f}s\")\n",
        "    return out"
      ],
      "metadata": {
        "id": "jCNweGDZI-qK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Create customers (dim)"
      ],
      "metadata": {
        "id": "AojaU9f8JHLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "n_customers = 50_000\n",
        "segments = [\"MASS\", \"AFFLUENT\", \"SME\"]\n",
        "risk = [\"LOW\", \"MED\", \"HIGH\"]\n",
        "\n",
        "seg_arr  = F.array(*[F.lit(x) for x in segments])\n",
        "risk_arr = F.array(*[F.lit(x) for x in risk])\n",
        "\n",
        "seg_idx = (F.pmod(F.col(\"id\"), F.lit(len(segments))) + F.lit(1)).cast(\"int\")\n",
        "risk_idx = (F.pmod(F.col(\"id\"), F.lit(len(risk))) + F.lit(1)).cast(\"int\")\n",
        "\n",
        "customers = (\n",
        "    spark.range(0, n_customers)\n",
        "    .select(\n",
        "        (F.col(\"id\") + F.lit(1)).cast(\"string\").alias(\"customer_id\"),\n",
        "        F.element_at(seg_arr, seg_idx).alias(\"segment\"),\n",
        "        F.element_at(risk_arr, risk_idx).alias(\"risk_tier\"),\n",
        "        # created_date: hôm trước - (id % 365) ngày\n",
        "        (F.date_sub(F.current_date(), (F.pmod(F.col(\"id\"), F.lit(365))).cast(\"int\"))).alias(\"created_date\"),\n",
        "    )\n",
        ")\n",
        "\n",
        "customers.cache()\n",
        "print(\"count =\", customers.count())\n",
        "customers.show(5, truncate=False)\n",
        "customers.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ER6QaemtJI8Z",
        "outputId": "9b798f95-245d-4b75-9c10-064026449cc3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count = 50000\n",
            "+-----------+--------+---------+------------+\n",
            "|customer_id|segment |risk_tier|created_date|\n",
            "+-----------+--------+---------+------------+\n",
            "|1          |MASS    |LOW      |2026-01-05  |\n",
            "|2          |AFFLUENT|MED      |2026-01-04  |\n",
            "|3          |SME     |HIGH     |2026-01-03  |\n",
            "|4          |MASS    |LOW      |2026-01-02  |\n",
            "|5          |AFFLUENT|MED      |2026-01-01  |\n",
            "+-----------+--------+---------+------------+\n",
            "only showing top 5 rows\n",
            "root\n",
            " |-- customer_id: string (nullable = false)\n",
            " |-- segment: string (nullable = false)\n",
            " |-- risk_tier: string (nullable = false)\n",
            " |-- created_date: date (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Create orders (fact) with skew customer_id"
      ],
      "metadata": {
        "id": "skScCUjYJ1vH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# orders: 2M rows (có thể giảm nếu Colab lag)\n",
        "n_orders = 2_000_000\n",
        "\n",
        "channels = [\"POS\", \"ECOM\", \"ATM\"]\n",
        "countries = [\"VN\", \"SG\", \"TH\", \"ID\", \"MY\"]\n",
        "statuses = [\"SUCCESS\", \"FAILED\", \"REVERSED\"]\n",
        "\n",
        "HOT_CUSTOMER = \"1\"   # hot key\n",
        "HOT_RATIO = 0.25     # 25% orders thuộc 1 customer (skew rõ)\n",
        "\n",
        "ch_arr = F.array(*[F.lit(x) for x in channels])\n",
        "print(f'test charr = {ch_arr}')\n",
        "ct_arr = F.array(*[F.lit(x) for x in countries])\n",
        "st_arr = F.array(*[F.lit(x) for x in statuses])\n",
        "\n",
        "ch_idx = (F.pmod(F.col(\"id\"), F.lit(len(channels))) + F.lit(1)).cast(\"int\")\n",
        "ct_idx = (F.pmod(F.col(\"id\"), F.lit(len(countries))) + F.lit(1)).cast(\"int\")\n",
        "st_idx = (F.pmod(F.col(\"id\"), F.lit(len(statuses))) + F.lit(1)).cast(\"int\")\n",
        "\n",
        "orders = (\n",
        "    spark.range(0, n_orders)\n",
        "    .select(\n",
        "        (F.col(\"id\") + 1).cast(\"string\").alias(\"order_id\"),\n",
        "\n",
        "        # skew: 25% = HOT_CUSTOMER, còn lại pseudo-random trong [2..n_customers]\n",
        "        F.when(F.rand(seed=7) < F.lit(HOT_RATIO), F.lit(HOT_CUSTOMER))\n",
        "         .otherwise((F.pmod(F.col(\"id\") * 17, F.lit(n_customers - 1)) + 2).cast(\"string\"))\n",
        "         .alias(\"customer_id\"),\n",
        "\n",
        "        (F.rand(seed=11) * 5000).cast(\"double\").alias(\"amount\"),\n",
        "\n",
        "        # timestamp: now - (id % 30) days\n",
        "        (F.current_timestamp() - F.expr(\"INTERVAL 1 DAYS\") - (F.pmod(F.col(\"id\"), F.lit(30)).cast(\"int\") * F.expr(\"INTERVAL 1 DAYS\")))\n",
        "          .alias(\"order_ts\"),\n",
        "\n",
        "        F.element_at(ch_arr, ch_idx).alias(\"channel\"),\n",
        "        F.element_at(ct_arr, ct_idx).alias(\"country\"),\n",
        "        F.element_at(st_arr, st_idx).alias(\"status\"),\n",
        "    )\n",
        ")\n",
        "\n",
        "orders.cache()\n",
        "print(\"orders count =\", orders.count())\n",
        "orders.show(5, truncate=False)\n",
        "orders.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21_73FhOJ3aO",
        "outputId": "edaa3838-0d61-4905-a0e0-3639486de436"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test charr = Column<'array('POS', 'ECOM', 'ATM')'>\n",
            "orders count = 2000000\n",
            "+--------+-----------+------------------+--------------------------+-------+-------+--------+\n",
            "|order_id|customer_id|amount            |order_ts                  |channel|country|status  |\n",
            "+--------+-----------+------------------+--------------------------+-------+-------+--------+\n",
            "|1       |2          |171.13196569036427|2026-01-04 06:43:43.452688|POS    |VN     |SUCCESS |\n",
            "|2       |19         |584.1125228224664 |2026-01-03 06:43:43.452688|ECOM   |SG     |FAILED  |\n",
            "|3       |36         |1626.1139047259715|2026-01-02 06:43:43.452688|ATM    |TH     |REVERSED|\n",
            "|4       |53         |2179.4255232405444|2026-01-01 06:43:43.452688|POS    |ID     |SUCCESS |\n",
            "|5       |70         |1391.575355397565 |2025-12-31 06:43:43.452688|ECOM   |MY     |FAILED  |\n",
            "+--------+-----------+------------------+--------------------------+-------+-------+--------+\n",
            "only showing top 5 rows\n",
            "root\n",
            " |-- order_id: string (nullable = false)\n",
            " |-- customer_id: string (nullable = true)\n",
            " |-- amount: double (nullable = false)\n",
            " |-- order_ts: timestamp (nullable = true)\n",
            " |-- channel: string (nullable = false)\n",
            " |-- country: string (nullable = false)\n",
            " |-- status: string (nullable = false)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LEVEL 1 — Transform/Action + Cache/Partition\n",
        "\n",
        "## Bài 1.1 — Lazy + cache đúng\n"
      ],
      "metadata": {
        "id": "x0Se0ZXWOnUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered = orders.filter(F.col(\"status\") == F.lit(\"SUCCESS\"))\n",
        "\n",
        "print(\"Explain BEFORE cache:\")\n",
        "filtered.explain()\n",
        "\n",
        "timed(\"count #1 (no cache)\", lambda: filtered.count())\n",
        "\n",
        "filtered_cached = filtered.cache()\n",
        "timed(\"count #2 (after cache)\", lambda: filtered_cached.count())\n",
        "\n",
        "print(\"Explain AFTER cache (có InMemoryTableScan/Cache):\")\n",
        "filtered_cached.explain()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9NFdYbCOuSe",
        "outputId": "120d93e2-b24c-4c43-d09d-9587c254374d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explain BEFORE cache:\n",
            "== Physical Plan ==\n",
            "*(1) Filter (status#233 = SUCCESS)\n",
            "+- InMemoryTableScan [order_id#227, customer_id#228, amount#229, order_ts#230, channel#231, country#232, status#233], [(status#233 = SUCCESS)]\n",
            "      +- InMemoryRelation [order_id#227, customer_id#228, amount#229, order_ts#230, channel#231, country#232, status#233], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "            +- *(1) Project [cast((id#226L + 1) as string) AS order_id#227, CASE WHEN (rand(7) < 0.25) THEN 1 ELSE cast((pmod((id#226L * 17), 49999) + 2) as string) END AS customer_id#228, (rand(11) * 5000.0) AS amount#229, 2026-01-04 06:43:43.452688 + -(INTERVAL '1' DAY * cast(pmod(id#226L, 30) as int)) AS order_ts#230, element_at([POS,ECOM,ATM], cast((pmod(id#226L, 3) + 1) as int), None, true) AS channel#231, element_at([VN,SG,TH,ID,MY], cast((pmod(id#226L, 5) + 1) as int), None, true) AS country#232, element_at([SUCCESS,FAILED,REVERSED], cast((pmod(id#226L, 3) + 1) as int), None, true) AS status#233]\n",
            "               +- *(1) Range (0, 2000000, step=1, splits=2)\n",
            "\n",
            "\n",
            "[count #1 (no cache)] took 1.19s\n",
            "[count #2 (after cache)] took 4.91s\n",
            "Explain AFTER cache (có InMemoryTableScan/Cache):\n",
            "== Physical Plan ==\n",
            "*(1) Filter (status#233 = SUCCESS)\n",
            "+- InMemoryTableScan [order_id#227, customer_id#228, amount#229, order_ts#230, channel#231, country#232, status#233], [(status#233 = SUCCESS)]\n",
            "      +- InMemoryRelation [order_id#227, customer_id#228, amount#229, order_ts#230, channel#231, country#232, status#233], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "            +- *(1) Project [cast((id#226L + 1) as string) AS order_id#227, CASE WHEN (rand(7) < 0.25) THEN 1 ELSE cast((pmod((id#226L * 17), 49999) + 2) as string) END AS customer_id#228, (rand(11) * 5000.0) AS amount#229, 2026-01-04 06:43:43.452688 + -(INTERVAL '1' DAY * cast(pmod(id#226L, 30) as int)) AS order_ts#230, element_at([POS,ECOM,ATM], cast((pmod(id#226L, 3) + 1) as int), None, true) AS channel#231, element_at([VN,SG,TH,ID,MY], cast((pmod(id#226L, 5) + 1) as int), None, true) AS country#232, element_at([SUCCESS,FAILED,REVERSED], cast((pmod(id#226L, 3) + 1) as int), None, true) AS status#233]\n",
            "               +- *(1) Range (0, 2000000, step=1, splits=2)\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bài 1.2 — repartition vs coalesce"
      ],
      "metadata": {
        "id": "cyGPF8ZUPMqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_small = orders.filter(F.col(\"country\") == F.lit(\"VN\"))\n",
        "\n",
        "print(\"Partitions original:\", orders_small.rdd.getNumPartitions())\n",
        "\n",
        "a = orders_small.repartition(200)\n",
        "print(\"Partitions after repartition(200):\", a.rdd.getNumPartitions())\n",
        "print(\"Explain repartition:\")\n",
        "a.explain()\n",
        "\n",
        "timed(\"repartition(200) count\", lambda: a.count())\n",
        "\n",
        "b = orders_small.coalesce(10)\n",
        "print(\"Partitions after coalesce(10):\", b.rdd.getNumPartitions())\n",
        "print(\"Explain coalesce:\")\n",
        "b.explain()\n",
        "\n",
        "timed(\"coalesce(10) count\", lambda: b.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFpK3h4JPT1A",
        "outputId": "a436b2e0-a606-4181-c420-d7d54623868a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Partitions original: 2\n",
            "Partitions after repartition(200): 200\n",
            "Explain repartition:\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=true\n",
            "+- == Final Plan ==\n",
            "   ResultQueryStage 2\n",
            "   +- ShuffleQueryStage 1\n",
            "      +- Exchange RoundRobinPartitioning(200), REPARTITION_BY_NUM, [plan_id=296]\n",
            "         +- *(1) Filter (country#232 = VN)\n",
            "            +- TableCacheQueryStage 0\n",
            "               +- InMemoryTableScan [order_id#227, customer_id#228, amount#229, order_ts#230, channel#231, country#232, status#233], [(country#232 = VN)]\n",
            "                     +- InMemoryRelation [order_id#227, customer_id#228, amount#229, order_ts#230, channel#231, country#232, status#233], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                           +- *(1) Project [cast((id#226L + 1) as string) AS order_id#227, CASE WHEN (rand(7) < 0.25) THEN 1 ELSE cast((pmod((id#226L * 17), 49999) + 2) as string) END AS customer_id#228, (rand(11) * 5000.0) AS amount#229, 2026-01-04 06:43:43.452688 + -(INTERVAL '1' DAY * cast(pmod(id#226L, 30) as int)) AS order_ts#230, element_at([POS,ECOM,ATM], cast((pmod(id#226L, 3) + 1) as int), None, true) AS channel#231, element_at([VN,SG,TH,ID,MY], cast((pmod(id#226L, 5) + 1) as int), None, true) AS country#232, element_at([SUCCESS,FAILED,REVERSED], cast((pmod(id#226L, 3) + 1) as int), None, true) AS status#233]\n",
            "                              +- *(1) Range (0, 2000000, step=1, splits=2)\n",
            "+- == Initial Plan ==\n",
            "   Exchange RoundRobinPartitioning(200), REPARTITION_BY_NUM, [plan_id=277]\n",
            "   +- Filter (country#232 = VN)\n",
            "      +- InMemoryTableScan [order_id#227, customer_id#228, amount#229, order_ts#230, channel#231, country#232, status#233], [(country#232 = VN)]\n",
            "            +- InMemoryRelation [order_id#227, customer_id#228, amount#229, order_ts#230, channel#231, country#232, status#233], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                  +- *(1) Project [cast((id#226L + 1) as string) AS order_id#227, CASE WHEN (rand(7) < 0.25) THEN 1 ELSE cast((pmod((id#226L * 17), 49999) + 2) as string) END AS customer_id#228, (rand(11) * 5000.0) AS amount#229, 2026-01-04 06:43:43.452688 + -(INTERVAL '1' DAY * cast(pmod(id#226L, 30) as int)) AS order_ts#230, element_at([POS,ECOM,ATM], cast((pmod(id#226L, 3) + 1) as int), None, true) AS channel#231, element_at([VN,SG,TH,ID,MY], cast((pmod(id#226L, 5) + 1) as int), None, true) AS country#232, element_at([SUCCESS,FAILED,REVERSED], cast((pmod(id#226L, 3) + 1) as int), None, true) AS status#233]\n",
            "                     +- *(1) Range (0, 2000000, step=1, splits=2)\n",
            "\n",
            "\n",
            "[repartition(200) count] took 5.36s\n",
            "Partitions after coalesce(10): 2\n",
            "Explain coalesce:\n",
            "== Physical Plan ==\n",
            "Coalesce 10\n",
            "+- *(1) Filter (country#232 = VN)\n",
            "   +- InMemoryTableScan [order_id#227, customer_id#228, amount#229, order_ts#230, channel#231, country#232, status#233], [(country#232 = VN)]\n",
            "         +- InMemoryRelation [order_id#227, customer_id#228, amount#229, order_ts#230, channel#231, country#232, status#233], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "               +- *(1) Project [cast((id#226L + 1) as string) AS order_id#227, CASE WHEN (rand(7) < 0.25) THEN 1 ELSE cast((pmod((id#226L * 17), 49999) + 2) as string) END AS customer_id#228, (rand(11) * 5000.0) AS amount#229, 2026-01-04 06:43:43.452688 + -(INTERVAL '1' DAY * cast(pmod(id#226L, 30) as int)) AS order_ts#230, element_at([POS,ECOM,ATM], cast((pmod(id#226L, 3) + 1) as int), None, true) AS channel#231, element_at([VN,SG,TH,ID,MY], cast((pmod(id#226L, 5) + 1) as int), None, true) AS country#232, element_at([SUCCESS,FAILED,REVERSED], cast((pmod(id#226L, 3) + 1) as int), None, true) AS status#233]\n",
            "                  +- *(1) Range (0, 2000000, step=1, splits=2)\n",
            "\n",
            "\n",
            "[coalesce(10) count] took 0.72s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LEVEL 2 — Join Strategies\n",
        "\n",
        "## Bài 2.1 — Join mặc định vs broadcast + tắt autobroadcast"
      ],
      "metadata": {
        "id": "A2L2jgEIPnn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (1) Join default\n",
        "print(\"=== DEFAULT JOIN ===\")\n",
        "orders.join(customers, \"customer_id\").explain()\n",
        "\n",
        "# (2) Force broadcast\n",
        "from pyspark.sql.functions import broadcast\n",
        "print(\"=== FORCE BROADCAST JOIN ===\")\n",
        "orders.join(broadcast(customers), \"customer_id\").explain()\n",
        "\n",
        "# (3) Disable auto broadcast\n",
        "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)\n",
        "print(\"=== AUTO BROADCAST DISABLED ===\")\n",
        "orders.join(customers, \"customer_id\").explain()\n",
        "\n",
        "# reset (optional)\n",
        "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", 10 * 1024 * 1024)  # 10MB default-ish"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAsjn0rZPtSa",
        "outputId": "a3b141a4-e99a-45e1-be37-5ffb70d68791"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== DEFAULT JOIN ===\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Project [customer_id#228, order_id#227, amount#229, order_ts#230, channel#231, country#232, status#233, segment#2, risk_tier#3, created_date#4]\n",
            "   +- BroadcastHashJoin [customer_id#228], [customer_id#1], Inner, BuildRight, false\n",
            "      :- Filter isnotnull(customer_id#228)\n",
            "      :  +- InMemoryTableScan [order_id#227, customer_id#228, amount#229, order_ts#230, channel#231, country#232, status#233], [isnotnull(customer_id#228)]\n",
            "      :        +- InMemoryRelation [order_id#227, customer_id#228, amount#229, order_ts#230, channel#231, country#232, status#233], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "      :              +- *(1) Project [cast((id#226L + 1) as string) AS order_id#227, CASE WHEN (rand(7) < 0.25) THEN 1 ELSE cast((pmod((id#226L * 17), 49999) + 2) as string) END AS customer_id#228, (rand(11) * 5000.0) AS amount#229, 2026-01-04 06:43:43.452688 + -(INTERVAL '1' DAY * cast(pmod(id#226L, 30) as int)) AS order_ts#230, element_at([POS,ECOM,ATM], cast((pmod(id#226L, 3) + 1) as int), None, true) AS channel#231, element_at([VN,SG,TH,ID,MY], cast((pmod(id#226L, 5) + 1) as int), None, true) AS country#232, element_at([SUCCESS,FAILED,REVERSED], cast((pmod(id#226L, 3) + 1) as int), None, true) AS status#233]\n",
            "      :                 +- *(1) Range (0, 2000000, step=1, splits=2)\n",
            "      +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false]),false), [plan_id=510]\n",
            "         +- InMemoryTableScan [customer_id#1, segment#2, risk_tier#3, created_date#4]\n",
            "               +- InMemoryRelation [customer_id#1, segment#2, risk_tier#3, created_date#4], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                     +- *(1) Project [cast((id#0L + 1) as string) AS customer_id#1, element_at([MASS,AFFLUENT,SME], cast((pmod(id#0L, 3) + 1) as int), None, true) AS segment#2, element_at([LOW,MED,HIGH], cast((pmod(id#0L, 3) + 1) as int), None, true) AS risk_tier#3, date_sub(2026-01-05, cast(pmod(id#0L, 365) as int)) AS created_date#4]\n",
            "                        +- *(1) Range (0, 50000, step=1, splits=2)\n",
            "\n",
            "\n",
            "=== FORCE BROADCAST JOIN ===\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Project [customer_id#228, order_id#227, amount#229, order_ts#230, channel#231, country#232, status#233, segment#2, risk_tier#3, created_date#4]\n",
            "   +- BroadcastHashJoin [customer_id#228], [customer_id#1], Inner, BuildRight, false\n",
            "      :- Filter isnotnull(customer_id#228)\n",
            "      :  +- InMemoryTableScan [order_id#227, customer_id#228, amount#229, order_ts#230, channel#231, country#232, status#233], [isnotnull(customer_id#228)]\n",
            "      :        +- InMemoryRelation [order_id#227, customer_id#228, amount#229, order_ts#230, channel#231, country#232, status#233], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "      :              +- *(1) Project [cast((id#226L + 1) as string) AS order_id#227, CASE WHEN (rand(7) < 0.25) THEN 1 ELSE cast((pmod((id#226L * 17), 49999) + 2) as string) END AS customer_id#228, (rand(11) * 5000.0) AS amount#229, 2026-01-04 06:43:43.452688 + -(INTERVAL '1' DAY * cast(pmod(id#226L, 30) as int)) AS order_ts#230, element_at([POS,ECOM,ATM], cast((pmod(id#226L, 3) + 1) as int), None, true) AS channel#231, element_at([VN,SG,TH,ID,MY], cast((pmod(id#226L, 5) + 1) as int), None, true) AS country#232, element_at([SUCCESS,FAILED,REVERSED], cast((pmod(id#226L, 3) + 1) as int), None, true) AS status#233]\n",
            "      :                 +- *(1) Range (0, 2000000, step=1, splits=2)\n",
            "      +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false]),false), [plan_id=531]\n",
            "         +- InMemoryTableScan [customer_id#1, segment#2, risk_tier#3, created_date#4]\n",
            "               +- InMemoryRelation [customer_id#1, segment#2, risk_tier#3, created_date#4], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                     +- *(1) Project [cast((id#0L + 1) as string) AS customer_id#1, element_at([MASS,AFFLUENT,SME], cast((pmod(id#0L, 3) + 1) as int), None, true) AS segment#2, element_at([LOW,MED,HIGH], cast((pmod(id#0L, 3) + 1) as int), None, true) AS risk_tier#3, date_sub(2026-01-05, cast(pmod(id#0L, 365) as int)) AS created_date#4]\n",
            "                        +- *(1) Range (0, 50000, step=1, splits=2)\n",
            "\n",
            "\n",
            "=== AUTO BROADCAST DISABLED ===\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Project [customer_id#228, order_id#227, amount#229, order_ts#230, channel#231, country#232, status#233, segment#2, risk_tier#3, created_date#4]\n",
            "   +- SortMergeJoin [customer_id#228], [customer_id#1], Inner\n",
            "      :- Sort [customer_id#228 ASC NULLS FIRST], false, 0\n",
            "      :  +- Exchange hashpartitioning(customer_id#228, 4), ENSURE_REQUIREMENTS, [plan_id=553]\n",
            "      :     +- Filter isnotnull(customer_id#228)\n",
            "      :        +- InMemoryTableScan [order_id#227, customer_id#228, amount#229, order_ts#230, channel#231, country#232, status#233], [isnotnull(customer_id#228)]\n",
            "      :              +- InMemoryRelation [order_id#227, customer_id#228, amount#229, order_ts#230, channel#231, country#232, status#233], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "      :                    +- *(1) Project [cast((id#226L + 1) as string) AS order_id#227, CASE WHEN (rand(7) < 0.25) THEN 1 ELSE cast((pmod((id#226L * 17), 49999) + 2) as string) END AS customer_id#228, (rand(11) * 5000.0) AS amount#229, 2026-01-04 06:43:43.452688 + -(INTERVAL '1' DAY * cast(pmod(id#226L, 30) as int)) AS order_ts#230, element_at([POS,ECOM,ATM], cast((pmod(id#226L, 3) + 1) as int), None, true) AS channel#231, element_at([VN,SG,TH,ID,MY], cast((pmod(id#226L, 5) + 1) as int), None, true) AS country#232, element_at([SUCCESS,FAILED,REVERSED], cast((pmod(id#226L, 3) + 1) as int), None, true) AS status#233]\n",
            "      :                       +- *(1) Range (0, 2000000, step=1, splits=2)\n",
            "      +- Sort [customer_id#1 ASC NULLS FIRST], false, 0\n",
            "         +- Exchange hashpartitioning(customer_id#1, 4), ENSURE_REQUIREMENTS, [plan_id=554]\n",
            "            +- InMemoryTableScan [customer_id#1, segment#2, risk_tier#3, created_date#4]\n",
            "                  +- InMemoryRelation [customer_id#1, segment#2, risk_tier#3, created_date#4], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                        +- *(1) Project [cast((id#0L + 1) as string) AS customer_id#1, element_at([MASS,AFFLUENT,SME], cast((pmod(id#0L, 3) + 1) as int), None, true) AS segment#2, element_at([LOW,MED,HIGH], cast((pmod(id#0L, 3) + 1) as int), None, true) AS risk_tier#3, date_sub(2026-01-05, cast(pmod(id#0L, 365) as int)) AS created_date#4]\n",
            "                           +- *(1) Range (0, 50000, step=1, splits=2)\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chạy thử timing join (nhẹ thôi)"
      ],
      "metadata": {
        "id": "Vh_zNmd6QBaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "joined = orders.join(customers, \"customer_id\")\n",
        "timed(\"join count()\", lambda: joined.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAhANwu5QCZx",
        "outputId": "ddcbc733-f4c3-4bc4-c091-a61e2f1e6254"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[join count()] took 2.10s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000000"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bài 2.2 — Join gây “đốt tiền” (customers_big)"
      ],
      "metadata": {
        "id": "TP3LkgQpQZ4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# phóng to customers bằng cách cross join với range nhỏ\n",
        "# chú ý: đừng phóng quá lớn kẻo Colab nổ RAM\n",
        "mult = 10\n",
        "customers_big = customers.crossJoin(spark.range(0, mult).select(F.col(\"id\").alias(\"k\"))).drop(\"k\")\n",
        "\n",
        "print(\"customers:\", customers.count())\n",
        "print(\"customers_big:\", customers_big.count())\n",
        "\n",
        "# join thử\n",
        "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", 10 * 1024 * 1024)  # bật lại\n",
        "print(\"=== JOIN orders with customers_big ===\")\n",
        "orders.join(customers_big, \"customer_id\").explain()\n",
        "\n",
        "timed(\"join customers_big count()\", lambda: orders.join(customers_big, \"customer_id\").count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cuPq-r6QbvZ",
        "outputId": "d6e111fb-c1f4-4f13-e405-c382311061ae"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "customers: 50000\n",
            "customers_big: 500000\n",
            "=== JOIN orders with customers_big ===\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Project [customer_id#228, order_id#227, amount#229, order_ts#230, channel#231, country#232, status#233, segment#2, risk_tier#3, created_date#4]\n",
            "   +- SortMergeJoin [customer_id#228], [customer_id#1], Inner\n",
            "      :- Sort [customer_id#228 ASC NULLS FIRST], false, 0\n",
            "      :  +- Exchange hashpartitioning(customer_id#228, 4), ENSURE_REQUIREMENTS, [plan_id=874]\n",
            "      :     +- Filter isnotnull(customer_id#228)\n",
            "      :        +- InMemoryTableScan [order_id#227, customer_id#228, amount#229, order_ts#230, channel#231, country#232, status#233], [isnotnull(customer_id#228)]\n",
            "      :              +- InMemoryRelation [order_id#227, customer_id#228, amount#229, order_ts#230, channel#231, country#232, status#233], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "      :                    +- *(1) Project [cast((id#226L + 1) as string) AS order_id#227, CASE WHEN (rand(7) < 0.25) THEN 1 ELSE cast((pmod((id#226L * 17), 49999) + 2) as string) END AS customer_id#228, (rand(11) * 5000.0) AS amount#229, 2026-01-04 06:43:43.452688 + -(INTERVAL '1' DAY * cast(pmod(id#226L, 30) as int)) AS order_ts#230, element_at([POS,ECOM,ATM], cast((pmod(id#226L, 3) + 1) as int), None, true) AS channel#231, element_at([VN,SG,TH,ID,MY], cast((pmod(id#226L, 5) + 1) as int), None, true) AS country#232, element_at([SUCCESS,FAILED,REVERSED], cast((pmod(id#226L, 3) + 1) as int), None, true) AS status#233]\n",
            "      :                       +- *(1) Range (0, 2000000, step=1, splits=2)\n",
            "      +- Sort [customer_id#1 ASC NULLS FIRST], false, 0\n",
            "         +- Exchange hashpartitioning(customer_id#1, 4), ENSURE_REQUIREMENTS, [plan_id=875]\n",
            "            +- BroadcastNestedLoopJoin BuildRight, Cross\n",
            "               :- InMemoryTableScan [customer_id#1, segment#2, risk_tier#3, created_date#4]\n",
            "               :     +- InMemoryRelation [customer_id#1, segment#2, risk_tier#3, created_date#4], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "               :           +- *(1) Project [cast((id#0L + 1) as string) AS customer_id#1, element_at([MASS,AFFLUENT,SME], cast((pmod(id#0L, 3) + 1) as int), None, true) AS segment#2, element_at([LOW,MED,HIGH], cast((pmod(id#0L, 3) + 1) as int), None, true) AS risk_tier#3, date_sub(2026-01-05, cast(pmod(id#0L, 365) as int)) AS created_date#4]\n",
            "               :              +- *(1) Range (0, 50000, step=1, splits=2)\n",
            "               +- BroadcastExchange IdentityBroadcastMode, [plan_id=870]\n",
            "                  +- Project\n",
            "                     +- Range (0, 10, step=1, splits=2)\n",
            "\n",
            "\n",
            "[join customers_big count()] took 5.75s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000000"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LEVEL 3 — Skew + Salting\n",
        "\n",
        "## Bài 3.1 — Detect skew nhanh"
      ],
      "metadata": {
        "id": "tNbi89sYQzb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders.groupBy(\"customer_id\").count().orderBy(F.desc(\"count\")).show(20, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QD8fhQ_Q3oQ",
        "outputId": "e7c9cd6b-007b-4f9e-f8ca-cbec426e22cf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------+\n",
            "|customer_id|count |\n",
            "+-----------+------+\n",
            "|1          |500755|\n",
            "|32714      |40    |\n",
            "|4313       |39    |\n",
            "|46379      |39    |\n",
            "|7413       |39    |\n",
            "|8935       |38    |\n",
            "|26025      |38    |\n",
            "|39886      |38    |\n",
            "|15245      |38    |\n",
            "|3731       |38    |\n",
            "|18348      |38    |\n",
            "|39393      |38    |\n",
            "|8281       |38    |\n",
            "|5447       |38    |\n",
            "|20013      |38    |\n",
            "|40015      |38    |\n",
            "|29221      |38    |\n",
            "|41091      |38    |\n",
            "|10279      |38    |\n",
            "|25600      |38    |\n",
            "+-----------+------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bài 3.2 — Salting (thực chiến)"
      ],
      "metadata": {
        "id": "LaprwWWIRM7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_SALT = 16  # số nhánh chia hot key\n",
        "\n",
        "# orders salted: chỉ salt với hot key\n",
        "orders_salted = (\n",
        "    orders.withColumn(\n",
        "        \"salt\",\n",
        "        F.when(F.col(\"customer_id\") == F.lit(HOT_CUSTOMER), (F.pmod(F.col(\"order_id\").cast(\"long\"), F.lit(N_SALT))).cast(\"int\"))\n",
        "         .otherwise(F.lit(0))\n",
        "    )\n",
        ")\n",
        "\n",
        "# customers salted: với hot key thì explode ra N_SALT bản ghi; còn lại salt=0\n",
        "customers_hot = customers.filter(F.col(\"customer_id\") == F.lit(HOT_CUSTOMER)) \\\n",
        "    .withColumn(\"salt\", F.explode(F.sequence(F.lit(0), F.lit(N_SALT - 1))))\n",
        "customers_cold = customers.filter(F.col(\"customer_id\") != F.lit(HOT_CUSTOMER)) \\\n",
        "    .withColumn(\"salt\", F.lit(0))\n",
        "\n",
        "customers_salted = customers_hot.unionByName(customers_cold)\n",
        "\n",
        "print(\"Explain salted join:\")\n",
        "orders_salted.join(customers_salted, [\"customer_id\", \"salt\"]).explain()\n",
        "\n",
        "timed(\"salted join count()\", lambda: orders_salted.join(customers_salted, [\"customer_id\", \"salt\"]).count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UjW8OgaROa7",
        "outputId": "b5b575c5-884f-4f71-8257-ea2bbd1a9adb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explain salted join:\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Project [customer_id#228, salt#3765, order_id#227, amount#229, order_ts#230, channel#231, country#232, status#233, segment#2, risk_tier#3, created_date#4]\n",
            "   +- BroadcastHashJoin [customer_id#228, salt#3765], [customer_id#1, salt#3767], Inner, BuildRight, false\n",
            "      :- Project [order_id#227, customer_id#228, amount#229, order_ts#230, channel#231, country#232, status#233, CASE WHEN (customer_id#228 = 1) THEN cast(pmod(cast(order_id#227 as bigint), 16) as int) ELSE 0 END AS salt#3765]\n",
            "      :  +- Filter ((isnotnull((customer_id#228 = 1)) AND isnotnull(customer_id#228)) AND CASE WHEN (customer_id#228 = 1) THEN isnotnull(cast(pmod(cast(order_id#227 as bigint), 16) as int)) ELSE true END)\n",
            "      :     +- InMemoryTableScan [amount#229, channel#231, country#232, customer_id#228, order_id#227, order_ts#230, status#233], [isnotnull((customer_id#228 = 1)), isnotnull(customer_id#228), CASE WHEN (customer_id#228 = 1) THEN isnotnull(cast(pmod(cast(order_id#227 as bigint), 16) as int)) ELSE true END]\n",
            "      :           +- InMemoryRelation [order_id#227, customer_id#228, amount#229, order_ts#230, channel#231, country#232, status#233], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "      :                 +- *(1) Project [cast((id#226L + 1) as string) AS order_id#227, CASE WHEN (rand(7) < 0.25) THEN 1 ELSE cast((pmod((id#226L * 17), 49999) + 2) as string) END AS customer_id#228, (rand(11) * 5000.0) AS amount#229, 2026-01-04 06:43:43.452688 + -(INTERVAL '1' DAY * cast(pmod(id#226L, 30) as int)) AS order_ts#230, element_at([POS,ECOM,ATM], cast((pmod(id#226L, 3) + 1) as int), None, true) AS channel#231, element_at([VN,SG,TH,ID,MY], cast((pmod(id#226L, 5) + 1) as int), None, true) AS country#232, element_at([SUCCESS,FAILED,REVERSED], cast((pmod(id#226L, 3) + 1) as int), None, true) AS status#233]\n",
            "      :                    +- *(1) Range (0, 2000000, step=1, splits=2)\n",
            "      +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false], input[4, int, false]),false), [plan_id=1296]\n",
            "         +- Union\n",
            "            :- Generate explode(org.apache.spark.sql.catalyst.expressions.UnsafeArrayData@f1dd012b), [customer_id#1, segment#2, risk_tier#3, created_date#4], false, [salt#3767]\n",
            "            :  +- Filter (customer_id#1 = 1)\n",
            "            :     +- InMemoryTableScan [customer_id#1, segment#2, risk_tier#3, created_date#4], [(customer_id#1 = 1)]\n",
            "            :           +- InMemoryRelation [customer_id#1, segment#2, risk_tier#3, created_date#4], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "            :                 +- *(1) Project [cast((id#0L + 1) as string) AS customer_id#1, element_at([MASS,AFFLUENT,SME], cast((pmod(id#0L, 3) + 1) as int), None, true) AS segment#2, element_at([LOW,MED,HIGH], cast((pmod(id#0L, 3) + 1) as int), None, true) AS risk_tier#3, date_sub(2026-01-05, cast(pmod(id#0L, 365) as int)) AS created_date#4]\n",
            "            :                    +- *(1) Range (0, 50000, step=1, splits=2)\n",
            "            +- Project [customer_id#3770, segment#3771, risk_tier#3772, created_date#3773, 0 AS salt#3768]\n",
            "               +- Filter NOT (customer_id#3770 = 1)\n",
            "                  +- InMemoryTableScan [created_date#3773, customer_id#3770, risk_tier#3772, segment#3771], [NOT (customer_id#3770 = 1)]\n",
            "                        +- InMemoryRelation [customer_id#3770, segment#3771, risk_tier#3772, created_date#3773], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                              +- *(1) Project [cast((id#0L + 1) as string) AS customer_id#1, element_at([MASS,AFFLUENT,SME], cast((pmod(id#0L, 3) + 1) as int), None, true) AS segment#2, element_at([LOW,MED,HIGH], cast((pmod(id#0L, 3) + 1) as int), None, true) AS risk_tier#3, date_sub(2026-01-05, cast(pmod(id#0L, 365) as int)) AS created_date#4]\n",
            "                                 +- *(1) Range (0, 50000, step=1, splits=2)\n",
            "\n",
            "\n",
            "[salted join count()] took 2.24s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000000"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LEVEL 4 — Gold-ish KPI + Window\n",
        "\n",
        "## Bài 4.1 — KPI theo ngày + segment"
      ],
      "metadata": {
        "id": "tQz4mv9r6Vn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_enriched = orders.join(customers, \"customer_id\") \\\n",
        "    .withColumn(\"order_date\", F.to_date(\"order_ts\"))\n",
        "\n",
        "kpi_daily = (orders_enriched\n",
        "    .groupBy(\"order_date\", \"segment\")\n",
        "    .agg(\n",
        "        F.count(\"*\").alias(\"txn_cnt\"),\n",
        "        F.sum(\"amount\").alias(\"revenue\"),\n",
        "        F.sum(F.when(F.col(\"status\") == \"SUCCESS\", 1).otherwise(0)).alias(\"success_cnt\")\n",
        "    )\n",
        "    .orderBy(\"order_date\", \"segment\")\n",
        ")\n",
        "\n",
        "kpi_daily.explain()\n",
        "kpi_daily.show(20, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGypcJpG6abW",
        "outputId": "87b098cb-3777-43d3-cf8a-ee9b411d413a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Sort [order_date#4389 ASC NULLS FIRST, segment#2 ASC NULLS FIRST], true, 0\n",
            "   +- Exchange rangepartitioning(order_date#4389 ASC NULLS FIRST, segment#2 ASC NULLS FIRST, 4), ENSURE_REQUIREMENTS, [plan_id=1583]\n",
            "      +- HashAggregate(keys=[order_date#4389, segment#2], functions=[count(1), sum(amount#229), sum(CASE WHEN (status#233 = SUCCESS) THEN 1 ELSE 0 END)])\n",
            "         +- Exchange hashpartitioning(order_date#4389, segment#2, 4), ENSURE_REQUIREMENTS, [plan_id=1580]\n",
            "            +- HashAggregate(keys=[order_date#4389, segment#2], functions=[partial_count(1), partial_sum(amount#229), partial_sum(CASE WHEN (status#233 = SUCCESS) THEN 1 ELSE 0 END)])\n",
            "               +- Project [amount#229, status#233, segment#2, cast(order_ts#230 as date) AS order_date#4389]\n",
            "                  +- BroadcastHashJoin [customer_id#228], [customer_id#1], Inner, BuildRight, false\n",
            "                     :- Filter isnotnull(customer_id#228)\n",
            "                     :  +- InMemoryTableScan [customer_id#228, amount#229, order_ts#230, status#233], [isnotnull(customer_id#228)]\n",
            "                     :        +- InMemoryRelation [order_id#227, customer_id#228, amount#229, order_ts#230, channel#231, country#232, status#233], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                     :              +- *(1) Project [cast((id#226L + 1) as string) AS order_id#227, CASE WHEN (rand(7) < 0.25) THEN 1 ELSE cast((pmod((id#226L * 17), 49999) + 2) as string) END AS customer_id#228, (rand(11) * 5000.0) AS amount#229, 2026-01-04 06:43:43.452688 + -(INTERVAL '1' DAY * cast(pmod(id#226L, 30) as int)) AS order_ts#230, element_at([POS,ECOM,ATM], cast((pmod(id#226L, 3) + 1) as int), None, true) AS channel#231, element_at([VN,SG,TH,ID,MY], cast((pmod(id#226L, 5) + 1) as int), None, true) AS country#232, element_at([SUCCESS,FAILED,REVERSED], cast((pmod(id#226L, 3) + 1) as int), None, true) AS status#233]\n",
            "                     :                 +- *(1) Range (0, 2000000, step=1, splits=2)\n",
            "                     +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false]),false), [plan_id=1575]\n",
            "                        +- InMemoryTableScan [customer_id#1, segment#2]\n",
            "                              +- InMemoryRelation [customer_id#1, segment#2, risk_tier#3, created_date#4], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                                    +- *(1) Project [cast((id#0L + 1) as string) AS customer_id#1, element_at([MASS,AFFLUENT,SME], cast((pmod(id#0L, 3) + 1) as int), None, true) AS segment#2, element_at([LOW,MED,HIGH], cast((pmod(id#0L, 3) + 1) as int), None, true) AS risk_tier#3, date_sub(2026-01-05, cast(pmod(id#0L, 365) as int)) AS created_date#4]\n",
            "                                       +- *(1) Range (0, 50000, step=1, splits=2)\n",
            "\n",
            "\n",
            "+----------+--------+-------+--------------------+-----------+\n",
            "|order_date|segment |txn_cnt|revenue             |success_cnt|\n",
            "+----------+--------+-------+--------------------+-----------+\n",
            "|2025-12-06|AFFLUENT|16762  |4.195748407022892E7 |0          |\n",
            "|2025-12-06|MASS    |33298  |8.325724175364585E7 |0          |\n",
            "|2025-12-06|SME     |16606  |4.1820216946777835E7|0          |\n",
            "|2025-12-07|AFFLUENT|16613  |4.1196803362770304E7|0          |\n",
            "|2025-12-07|MASS    |33392  |8.370199692691499E7 |0          |\n",
            "|2025-12-07|SME     |16661  |4.164091980095109E7 |0          |\n",
            "|2025-12-08|AFFLUENT|16610  |4.165618406910464E7 |16610      |\n",
            "|2025-12-08|MASS    |33421  |8.352923292688581E7 |33421      |\n",
            "|2025-12-08|SME     |16635  |4.147690744490528E7 |16635      |\n",
            "|2025-12-09|AFFLUENT|16678  |4.163808342986485E7 |0          |\n",
            "|2025-12-09|MASS    |33402  |8.344168377215199E7 |0          |\n",
            "|2025-12-09|SME     |16586  |4.1393765454217896E7|0          |\n",
            "|2025-12-10|AFFLUENT|16519  |4.113145002008035E7 |0          |\n",
            "|2025-12-10|MASS    |33390  |8.32062603473356E7  |0          |\n",
            "|2025-12-10|SME     |16757  |4.184957245934688E7 |0          |\n",
            "|2025-12-11|AFFLUENT|16678  |4.183881558508842E7 |16678      |\n",
            "|2025-12-11|MASS    |33356  |8.355772943203944E7 |33356      |\n",
            "|2025-12-11|SME     |16632  |4.135872646211739E7 |16632      |\n",
            "|2025-12-12|AFFLUENT|16695  |4.140139395191114E7 |0          |\n",
            "|2025-12-12|MASS    |33265  |8.327307041631016E7 |0          |\n",
            "+----------+--------+-------+--------------------+-----------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bài 4.2 — Window: top 10 customers mỗi ngày theo revenue"
      ],
      "metadata": {
        "id": "I_5BvMr46ovy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "\n",
        "daily_by_customer = (orders\n",
        "    .withColumn(\"order_date\", F.to_date(\"order_ts\"))\n",
        "    .groupBy(\"order_date\", \"customer_id\")\n",
        "    .agg(F.sum(\"amount\").alias(\"daily_revenue\"))\n",
        ")\n",
        "\n",
        "w = Window.partitionBy(\"order_date\").orderBy(F.desc(\"daily_revenue\"))\n",
        "\n",
        "top10 = (daily_by_customer\n",
        "    .withColumn(\"rk\", F.dense_rank().over(w))\n",
        "    .filter(F.col(\"rk\") <= 10)\n",
        "    .orderBy(\"order_date\", \"rk\")\n",
        ")\n",
        "\n",
        "top10.explain()\n",
        "top10.show(50, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHztSPzw6rWz",
        "outputId": "c4ec2306-5dd6-4a6e-c509-8d70ca7ea0c2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Sort [order_date#4877 ASC NULLS FIRST, rk#4888 ASC NULLS FIRST], true, 0\n",
            "   +- Exchange rangepartitioning(order_date#4877 ASC NULLS FIRST, rk#4888 ASC NULLS FIRST, 4), ENSURE_REQUIREMENTS, [plan_id=1792]\n",
            "      +- Filter (rk#4888 <= 10)\n",
            "         +- Window [dense_rank(daily_revenue#4878) windowspecdefinition(order_date#4877, daily_revenue#4878 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rk#4888], [order_date#4877], [daily_revenue#4878 DESC NULLS LAST]\n",
            "            +- WindowGroupLimit [order_date#4877], [daily_revenue#4878 DESC NULLS LAST], dense_rank(daily_revenue#4878), 10, Final\n",
            "               +- Sort [order_date#4877 ASC NULLS FIRST, daily_revenue#4878 DESC NULLS LAST], false, 0\n",
            "                  +- Exchange hashpartitioning(order_date#4877, 4), ENSURE_REQUIREMENTS, [plan_id=1786]\n",
            "                     +- WindowGroupLimit [order_date#4877], [daily_revenue#4878 DESC NULLS LAST], dense_rank(daily_revenue#4878), 10, Partial\n",
            "                        +- Sort [order_date#4877 ASC NULLS FIRST, daily_revenue#4878 DESC NULLS LAST], false, 0\n",
            "                           +- HashAggregate(keys=[order_date#4877, customer_id#228], functions=[sum(amount#229)])\n",
            "                              +- Exchange hashpartitioning(order_date#4877, customer_id#228, 4), ENSURE_REQUIREMENTS, [plan_id=1780]\n",
            "                                 +- HashAggregate(keys=[order_date#4877, customer_id#228], functions=[partial_sum(amount#229)])\n",
            "                                    +- Project [customer_id#228, amount#229, cast(order_ts#230 as date) AS order_date#4877]\n",
            "                                       +- InMemoryTableScan [amount#229, customer_id#228, order_ts#230]\n",
            "                                             +- InMemoryRelation [order_id#227, customer_id#228, amount#229, order_ts#230, channel#231, country#232, status#233], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                                                   +- *(1) Project [cast((id#226L + 1) as string) AS order_id#227, CASE WHEN (rand(7) < 0.25) THEN 1 ELSE cast((pmod((id#226L * 17), 49999) + 2) as string) END AS customer_id#228, (rand(11) * 5000.0) AS amount#229, 2026-01-04 06:43:43.452688 + -(INTERVAL '1' DAY * cast(pmod(id#226L, 30) as int)) AS order_ts#230, element_at([POS,ECOM,ATM], cast((pmod(id#226L, 3) + 1) as int), None, true) AS channel#231, element_at([VN,SG,TH,ID,MY], cast((pmod(id#226L, 5) + 1) as int), None, true) AS country#232, element_at([SUCCESS,FAILED,REVERSED], cast((pmod(id#226L, 3) + 1) as int), None, true) AS status#233]\n",
            "                                                      +- *(1) Range (0, 2000000, step=1, splits=2)\n",
            "\n",
            "\n",
            "+----------+-----------+--------------------+---+\n",
            "|order_date|customer_id|daily_revenue       |rk |\n",
            "+----------+-----------+--------------------+---+\n",
            "|2025-12-06|1          |4.173162568441701E7 |1  |\n",
            "|2025-12-06|34472      |9940.09967381808    |2  |\n",
            "|2025-12-06|29762      |9932.800316742989   |3  |\n",
            "|2025-12-06|45341      |9915.146947797892   |4  |\n",
            "|2025-12-06|16740      |9907.350437984041   |5  |\n",
            "|2025-12-06|4319       |9905.377850164425   |6  |\n",
            "|2025-12-06|33411      |9879.674964148704   |7  |\n",
            "|2025-12-06|10113      |9840.20538215006    |8  |\n",
            "|2025-12-06|7708       |9813.134520814321   |9  |\n",
            "|2025-12-06|31254      |9809.28440010234    |10 |\n",
            "|2025-12-07|1          |4.158727859207556E7 |1  |\n",
            "|2025-12-07|43791      |9904.234879810008   |2  |\n",
            "|2025-12-07|2737       |9849.78455705429    |3  |\n",
            "|2025-12-07|31550      |9845.34836782363    |4  |\n",
            "|2025-12-07|42992      |9843.41456049506    |5  |\n",
            "|2025-12-07|8262       |9843.083920390825   |6  |\n",
            "|2025-12-07|11113      |9809.880247162277   |7  |\n",
            "|2025-12-07|35158      |9780.94829090802    |8  |\n",
            "|2025-12-07|34044      |9776.873739589699   |9  |\n",
            "|2025-12-07|41313      |9764.791681510098   |10 |\n",
            "|2025-12-08|1          |4.1883811045421615E7|1  |\n",
            "|2025-12-08|49184      |9948.639972005172   |2  |\n",
            "|2025-12-08|28154      |9920.998653976767   |3  |\n",
            "|2025-12-08|47505      |9867.358324973906   |4  |\n",
            "|2025-12-08|42681      |9848.693692520996   |5  |\n",
            "|2025-12-08|13338      |9816.169401674855   |6  |\n",
            "|2025-12-08|25176      |9811.979466104915   |7  |\n",
            "|2025-12-08|9670       |9795.595066706705   |8  |\n",
            "|2025-12-08|9521       |9789.005003799448   |9  |\n",
            "|2025-12-08|41344      |9787.79844057824    |10 |\n",
            "|2025-12-09|1          |4.1949346013080664E7|1  |\n",
            "|2025-12-09|29153      |9973.445815168761   |2  |\n",
            "|2025-12-09|33762      |9940.207028984918   |3  |\n",
            "|2025-12-09|4987       |9937.885944652433   |4  |\n",
            "|2025-12-09|13062      |9909.391166933172   |5  |\n",
            "|2025-12-09|33648      |9894.782546911862   |6  |\n",
            "|2025-12-09|23299      |9891.90905326795    |7  |\n",
            "|2025-12-09|8411       |9885.670811087964   |8  |\n",
            "|2025-12-09|25596      |9864.112009003562   |9  |\n",
            "|2025-12-09|4398       |9852.026430022583   |10 |\n",
            "|2025-12-10|1          |4.161905001687335E7 |1  |\n",
            "|2025-12-10|24160      |9941.348242190455   |2  |\n",
            "|2025-12-10|27033      |9922.134919181895   |3  |\n",
            "|2025-12-10|37499      |9893.055679601111   |4  |\n",
            "|2025-12-10|23742      |9863.015857434322   |5  |\n",
            "|2025-12-10|5483       |9816.339081368895   |6  |\n",
            "|2025-12-10|18164      |9802.521974374697   |7  |\n",
            "|2025-12-10|44953      |9793.78076419036    |8  |\n",
            "|2025-12-10|23473      |9793.479377149184   |9  |\n",
            "|2025-12-10|37015      |9755.263300381619   |10 |\n",
            "+----------+-----------+--------------------+---+\n",
            "only showing top 50 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LEVEL 5 — Idempotent output (mô phỏng local)\n",
        "\n",
        "Colab không có GCS mặc định, nên mình demo output ra /content/output/... để bạn hiểu “idempotent partition overwrite”."
      ],
      "metadata": {
        "id": "Pp5QLBbu68K-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "base_path = \"/content/output/gold/orders_kpi\"\n",
        "dt = \"2025-01-05\"  # thử đổi dt\n",
        "\n",
        "out_path = f\"{base_path}/dt={dt}\"\n",
        "\n",
        "# giả lập: mỗi lần rerun cùng dt => overwrite đúng partition dt\n",
        "(\n",
        "    kpi_daily.filter(F.col(\"order_date\") == F.lit(dt))\n",
        "    .write.mode(\"overwrite\")\n",
        "    .parquet(out_path)\n",
        ")\n",
        "\n",
        "print(\"Wrote:\", out_path)\n",
        "print(\"Files:\", os.listdir(out_path)[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65o-5PvK7BX0",
        "outputId": "062d4090-3177-4b56-9ac9-37fb35d2b1e3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote: /content/output/gold/orders_kpi/dt=2025-01-05\n",
            "Files: ['_SUCCESS', '._SUCCESS.crc', 'part-00000-0f00c31e-0aa3-4ab2-ae77-3b9c96029297-c000.snappy.parquet', '.part-00000-0f00c31e-0aa3-4ab2-ae77-3b9c96029297-c000.snappy.parquet.crc']\n"
          ]
        }
      ]
    }
  ]
}