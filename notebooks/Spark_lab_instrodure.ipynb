{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNp+I22d/fdq5rz3taJ4DgU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nptan2005/spark401_colab/blob/main/notebooks/Spark_lab_instrodure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LMqmfblitAYy",
        "outputId": "e4605034-7e06-4183-a4d0-6b9b7f44c608"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  at-spi2-core fonts-dejavu-core fonts-dejavu-extra gsettings-desktop-schemas\n",
            "  libatk-bridge2.0-0 libatk-wrapper-java libatk-wrapper-java-jni libatk1.0-0\n",
            "  libatk1.0-data libatspi2.0-0 libgail-common libgail18 libgtk2.0-0\n",
            "  libgtk2.0-bin libgtk2.0-common librsvg2-common libxcomposite1 libxt-dev\n",
            "  libxtst6 libxxf86dga1 openjdk-17-jre session-migration x11-utils\n",
            "Suggested packages:\n",
            "  gvfs libxt-doc openjdk-17-demo openjdk-17-source visualvm mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  at-spi2-core fonts-dejavu-core fonts-dejavu-extra gsettings-desktop-schemas\n",
            "  libatk-bridge2.0-0 libatk-wrapper-java libatk-wrapper-java-jni libatk1.0-0\n",
            "  libatk1.0-data libatspi2.0-0 libgail-common libgail18 libgtk2.0-0\n",
            "  libgtk2.0-bin libgtk2.0-common librsvg2-common libxcomposite1 libxt-dev\n",
            "  libxtst6 libxxf86dga1 openjdk-17-jdk openjdk-17-jre session-migration\n",
            "  x11-utils\n",
            "0 upgraded, 24 newly installed, 0 to remove and 1 not upgraded.\n",
            "Need to get 8,212 kB of archives.\n",
            "After this operation, 24.2 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatspi2.0-0 amd64 2.44.0-3 [80.9 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 session-migration amd64 0.3.6 [9,774 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 gsettings-desktop-schemas all 42.0-1ubuntu1 [31.1 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 at-spi2-core amd64 2.44.0-3 [54.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk1.0-data all 2.36.0-3build1 [2,824 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk1.0-0 amd64 2.36.0-3build1 [51.9 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-bridge2.0-0 amd64 2.38.0-3 [66.6 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcomposite1 amd64 1:0.4.5-1build2 [7,192 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java all 0.38.0-5build1 [53.1 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java-jni amd64 0.38.0-5build1 [49.0 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-common all 2.24.33-2ubuntu2.1 [125 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-0 amd64 2.24.33-2ubuntu2.1 [2,038 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail18 amd64 2.24.33-2ubuntu2.1 [15.9 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail-common amd64 2.24.33-2ubuntu2.1 [132 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-bin amd64 2.24.33-2ubuntu2.1 [7,936 B]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 librsvg2-common amd64 2.52.5+dfsg-3ubuntu0.2 [17.7 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jre amd64 17.0.17+10-1~22.04 [238 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jdk amd64 17.0.17+10-1~22.04 [1,521 kB]\n",
            "Fetched 8,212 kB in 1s (7,282 kB/s)\n",
            "Selecting previously unselected package libatspi2.0-0:amd64.\n",
            "(Reading database ... 117528 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libatspi2.0-0_2.44.0-3_amd64.deb ...\n",
            "Unpacking libatspi2.0-0:amd64 (2.44.0-3) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../01-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package session-migration.\n",
            "Preparing to unpack .../02-session-migration_0.3.6_amd64.deb ...\n",
            "Unpacking session-migration (0.3.6) ...\n",
            "Selecting previously unselected package gsettings-desktop-schemas.\n",
            "Preparing to unpack .../03-gsettings-desktop-schemas_42.0-1ubuntu1_all.deb ...\n",
            "Unpacking gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Selecting previously unselected package at-spi2-core.\n",
            "Preparing to unpack .../04-at-spi2-core_2.44.0-3_amd64.deb ...\n",
            "Unpacking at-spi2-core (2.44.0-3) ...\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "Preparing to unpack .../05-fonts-dejavu-core_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-2build1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../06-fonts-dejavu-extra_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-2build1) ...\n",
            "Selecting previously unselected package libatk1.0-data.\n",
            "Preparing to unpack .../07-libatk1.0-data_2.36.0-3build1_all.deb ...\n",
            "Unpacking libatk1.0-data (2.36.0-3build1) ...\n",
            "Selecting previously unselected package libatk1.0-0:amd64.\n",
            "Preparing to unpack .../08-libatk1.0-0_2.36.0-3build1_amd64.deb ...\n",
            "Unpacking libatk1.0-0:amd64 (2.36.0-3build1) ...\n",
            "Selecting previously unselected package libatk-bridge2.0-0:amd64.\n",
            "Preparing to unpack .../09-libatk-bridge2.0-0_2.38.0-3_amd64.deb ...\n",
            "Unpacking libatk-bridge2.0-0:amd64 (2.38.0-3) ...\n",
            "Selecting previously unselected package libxcomposite1:amd64.\n",
            "Preparing to unpack .../10-libxcomposite1_1%3a0.4.5-1build2_amd64.deb ...\n",
            "Unpacking libxcomposite1:amd64 (1:0.4.5-1build2) ...\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "Preparing to unpack .../11-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../12-x11-utils_7.7+5build2_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+5build2) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../13-libatk-wrapper-java_0.38.0-5build1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../14-libatk-wrapper-java-jni_0.38.0-5build1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "Preparing to unpack .../15-libgtk2.0-common_2.24.33-2ubuntu2.1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../16-libgtk2.0-0_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../17-libgail18_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../18-libgail-common_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../19-libgtk2.0-bin_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package librsvg2-common:amd64.\n",
            "Preparing to unpack .../20-librsvg2-common_2.52.5+dfsg-3ubuntu0.2_amd64.deb ...\n",
            "Unpacking librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Selecting previously unselected package libxt-dev:amd64.\n",
            "Preparing to unpack .../21-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n",
            "Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Selecting previously unselected package openjdk-17-jre:amd64.\n",
            "Preparing to unpack .../22-openjdk-17-jre_17.0.17+10-1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-17-jre:amd64 (17.0.17+10-1~22.04) ...\n",
            "Selecting previously unselected package openjdk-17-jdk:amd64.\n",
            "Preparing to unpack .../23-openjdk-17-jdk_17.0.17+10-1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-17-jdk:amd64 (17.0.17+10-1~22.04) ...\n",
            "Setting up session-migration (0.3.6) ...\n",
            "Created symlink /etc/systemd/user/graphical-session-pre.target.wants/session-migration.service ‚Üí /usr/lib/systemd/user/session-migration.service.\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Setting up libatspi2.0-0:amd64 (2.44.0-3) ...\n",
            "Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Setting up fonts-dejavu-core (2.37-2build1) ...\n",
            "Setting up librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Setting up libatk1.0-data (2.36.0-3build1) ...\n",
            "Setting up fonts-dejavu-extra (2.37-2build1) ...\n",
            "Setting up libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libatk1.0-0:amd64 (2.36.0-3build1) ...\n",
            "Setting up libxcomposite1:amd64 (1:0.4.5-1build2) ...\n",
            "Setting up gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Setting up libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libatk-bridge2.0-0:amd64 (2.38.0-3) ...\n",
            "Setting up libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Setting up x11-utils (7.7+5build2) ...\n",
            "Setting up libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Setting up libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up openjdk-17-jre:amd64 (17.0.17+10-1~22.04) ...\n",
            "Setting up openjdk-17-jdk:amd64 (17.0.17+10-1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Processing triggers for libgdk-pixbuf-2.0-0:amd64 (2.42.8+dfsg-1ubuntu0.4) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libglib2.0-0:amd64 (2.72.4-0ubuntu2.6) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.11) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Setting up at-spi2-core (2.44.0-3) ...\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y openjdk-17-jdk"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üéØ M·ª•c ti√™u luy·ªán Spark tr√™n Google Colab:\n",
        "> *\tCh·∫°y Spark 4.0.1 th·∫≠t (kh√¥ng gi·∫£ l·∫≠p)\n",
        "> *\tVi·∫øt PySpark gi·ªëng production\n",
        "> *\t**Luy·ªán:**\n",
        ">>-\tDataFrame API\n",
        ">>-\tTransformation vs Action\n",
        ">>-\tPartition / Shuffle\n",
        ">>-\tBasic optimization mindset\n",
        ">>-\tKh√¥ng ph·ª• thu·ªôc GCP quota / Dataproc\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "  ## üß± Ki·∫øn tr√∫c khi ch·∫°y Spark tr√™n Colab\n",
        "\n",
        "\n",
        "\n",
        "```mermaid\n",
        "flowchart LR\n",
        "    A[Google Colab Notebook] --> B[Local Spark 4.0.1]\n",
        "    B --> C[In-memory DataFrame]\n",
        "    B --> D[Local Disk /content]\n",
        "```\n",
        "> ‚ö†Ô∏è Spark ch·∫°y local mode, kh√¥ng ph·∫£i cluster ‚Äì nh∆∞ng API & t∆∞ duy y h·ªát Dataproc\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ STEP 1 ‚Äì T·∫°o Notebook Colab\n",
        "1.\tM·ªü: https://colab.research.google.com\n",
        "2.\tNew Notebook\n",
        "3.\tRuntime ‚Üí Python 3\n",
        "4.\t(Optional) Runtime ‚Üí Change runtime ‚Üí High-RAM n·∫øu c√≥\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ STEP 2 ‚Äì C√†i Java (B·∫ÆT BU·ªòC)\n",
        "\n",
        "Spark c·∫ßn Java ‚â• 11\n",
        "\n",
        "\n",
        "\n",
        "```python\n",
        "!apt-get install -y openjdk-17-jdk\n",
        "```\n",
        "\n",
        "Ki·ªÉm tra:\n",
        "\n",
        "```python\n",
        "!java -version\n",
        "```"
      ],
      "metadata": {
        "id": "WKX2bOA7w9ey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!java -version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8v4j0ehtvyo",
        "outputId": "2f0b45b8-fc7e-4781-cf55-c7347d05275e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"17.0.17\" 2025-10-21\n",
            "OpenJDK Runtime Environment (build 17.0.17+10-Ubuntu-122.04)\n",
            "OpenJDK 64-Bit Server VM (build 17.0.17+10-Ubuntu-122.04, mixed mode, sharing)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîπ STEP 3 ‚Äì C√†i Spark 4.0.1\n",
        "\n",
        "```python\n",
        "!wget https://archive.apache.org/dist/spark/spark-4.0.1/spark-4.0.1-bin-hadoop3.tgz\n",
        "!tar xf spark-4.0.1-bin-hadoop3.tgz\n",
        "```"
      ],
      "metadata": {
        "id": "XpSwAHZAzjO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://archive.apache.org/dist/spark/spark-4.0.1/spark-4.0.1-bin-hadoop3.tgz\n",
        "!tar xf spark-4.0.1-bin-hadoop3.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5B727ynt2z7",
        "outputId": "1231c0f9-7438-4ff5-daab-4c5a543d0e23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-29 06:06:53--  https://archive.apache.org/dist/spark/spark-4.0.1/spark-4.0.1-bin-hadoop3.tgz\n",
            "Resolving archive.apache.org (archive.apache.org)... 65.108.204.189, 2a01:4f9:1a:a084::2\n",
            "Connecting to archive.apache.org (archive.apache.org)|65.108.204.189|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 548955321 (524M) [application/x-gzip]\n",
            "Saving to: ‚Äòspark-4.0.1-bin-hadoop3.tgz‚Äô\n",
            "\n",
            "spark-4.0.1-bin-had 100%[===================>] 523.52M  24.3MB/s    in 23s     \n",
            "\n",
            "2025-12-29 06:07:17 (22.7 MB/s) - ‚Äòspark-4.0.1-bin-hadoop3.tgz‚Äô saved [548955321/548955321]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîπ STEP 4 ‚Äì Set ENV cho Spark\n",
        "\n",
        "```python\n",
        "import os\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-17-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-4.0.1-bin-hadoop3\"\n",
        "os.environ[\"PATH\"] += \":/content/spark-4.0.1-bin-hadoop3/bin\"\n",
        "```\n",
        "\n",
        "ki·ªÉm tra:\n",
        "\n",
        "```python\n",
        "!spark-submit --version\n",
        "```\n",
        ">üëâ Ph·∫£i th·∫•y: Spark version 4.0.1"
      ],
      "metadata": {
        "id": "8-tbilqWzX29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-17-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-4.0.1-bin-hadoop3\"\n",
        "os.environ[\"PATH\"] += \":/content/spark-4.0.1-bin-hadoop3/bin\""
      ],
      "metadata": {
        "id": "SepvMIpFuAnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!spark-submit --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTPqfqWNuGJB",
        "outputId": "e2cba0b6-811d-473a-806c-de95a3d2b744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Using incubator modules: jdk.incubator.vector\n",
            "Welcome to\n",
            "      ____              __\n",
            "     / __/__  ___ _____/ /__\n",
            "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
            "   /___/ .__/\\_,_/_/ /_/\\_\\   version 4.0.1\n",
            "      /_/\n",
            "                        \n",
            "Using Scala version 2.13.16, OpenJDK 64-Bit Server VM, 17.0.17\n",
            "Branch HEAD\n",
            "Compiled by user runner on 2025-09-02T03:10:51Z\n",
            "Revision 29434ea766b0fc3c3bf6eaadb43a8f931133649e\n",
            "Url https://github.com/apache/spark\n",
            "Type --help for more information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîπ STEP 5 ‚Äì C√†i PySpark t∆∞∆°ng th√≠ch\n",
        "\n",
        "```bash\n",
        "!pip install pyspark==4.0.1\n",
        "```"
      ],
      "metadata": {
        "id": "LBmKVvyjz-kQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark==4.0.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NROMrDgpuKY6",
        "outputId": "65c45805-1c8b-4c06-efe4-db3769c0236e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark==4.0.1 in /usr/local/lib/python3.12/dist-packages (4.0.1)\n",
            "Requirement already satisfied: py4j==0.10.9.9 in /usr/local/lib/python3.12/dist-packages (from pyspark==4.0.1) (0.10.9.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "A3P7Kkgx0JbI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîπ STEP 6 ‚Äì T·∫°o SparkSession (chu·∫©n production mindset)\n",
        "\n",
        "```python\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = (\n",
        "    SparkSession.builder\n",
        "    .appName(\"Spark401-Colab-Training\")\n",
        "    .master(\"local[*]\")\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"4\")\n",
        "    .config(\"spark.driver.memory\", \"4g\")\n",
        "    .getOrCreate()\n",
        ")\n",
        "\n",
        "spark\n",
        "```"
      ],
      "metadata": {
        "id": "wStZEXGlzK70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# T·∫°o SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = (\n",
        "    SparkSession.builder\n",
        "    .appName(\"Spark401-Colab-Training\")\n",
        "    .master(\"local[*]\")\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"4\")\n",
        "    .config(\"spark.driver.memory\", \"4g\")\n",
        "    .getOrCreate()\n",
        ")\n",
        "\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "X0wM5cVKuhtQ",
        "outputId": "847da9c3-925b-4567-a8bd-139e7e04a6eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7a521417c2c0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://23945b9ebf3f:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v4.0.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark401-Colab-Training</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîπ STEP 7 ‚Äì B√†i t·∫≠p Spark C∆† B·∫¢N (R·∫§T QUAN TR·ªåNG)"
      ],
      "metadata": {
        "id": "ebQVSkoT0W9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7.1 T·∫°o DataFrame:\n",
        "\n",
        "```python\n",
        "data = [\n",
        "    (1, \"A\", 100),\n",
        "    (2, \"A\", 200),\n",
        "    (3, \"B\", 300),\n",
        "    (4, \"B\", 400),\n",
        "    (5, \"C\", 500),\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(data, [\"id\", \"group\", \"amount\"])\n",
        "df.show()\n",
        "```"
      ],
      "metadata": {
        "id": "FTBAK1180ebV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# T·∫°o DataFrame\n",
        "data = [\n",
        "    (1, \"A\", 100),\n",
        "    (2, \"A\", 200),\n",
        "    (3, \"B\", 300),\n",
        "    (4, \"B\", 400),\n",
        "    (5, \"C\", 500),\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(data, [\"id\", \"group\", \"amount\"])\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0NKcypzusyF",
        "outputId": "b25327d4-66ac-4b21-8ebb-13578855bd80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+------+\n",
            "| id|group|amount|\n",
            "+---+-----+------+\n",
            "|  1|    A|   100|\n",
            "|  2|    A|   200|\n",
            "|  3|    B|   300|\n",
            "|  4|    B|   400|\n",
            "|  5|    C|   500|\n",
            "+---+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7.2 Transformation vs Action:\n",
        "\n",
        "```python\n",
        "df2 = df.filter(df.amount > 200)   # transformation\n",
        "```\n",
        "\n",
        "Ch∆∞a ch·∫°y g√¨ c·∫£ üëá\n",
        "\n",
        "```python\n",
        "df2.explain()\n",
        "```\n",
        "\n",
        "Ch·∫°y action:\n",
        "\n",
        "```python\n",
        "df2.show()\n",
        "```\n",
        "\n",
        "> üëâ Key mindset: Spark ch·ªâ ch·∫°y khi c√≥ action"
      ],
      "metadata": {
        "id": "yNr-8vRF0sR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformation vs Action\n",
        "df2 = df.filter(df.amount > 200)   # transformation"
      ],
      "metadata": {
        "id": "jJSnc_vKuy83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.explain()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fsrl7dIduzZ3",
        "outputId": "bba57c6c-eee1-4a6d-a8c5-9ead89295ebf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "*(1) Filter (isnotnull(amount#2L) AND (amount#2L > 200))\n",
            "+- *(1) Scan ExistingRDD[id#0L,group#1,amount#2L]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# action\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TS0UKbFu499",
        "outputId": "9df85e17-8615-4ce1-f911-0fdedc6216cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+------+\n",
            "| id|group|amount|\n",
            "+---+-----+------+\n",
            "|  3|    B|   300|\n",
            "|  4|    B|   400|\n",
            "|  5|    C|   500|\n",
            "+---+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7.3 GroupBy + Aggregation"
      ],
      "metadata": {
        "id": "m0-hqqSz1UFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GroupBy + Aggregation\n",
        "from pyspark.sql.functions import sum, avg\n",
        "\n",
        "df.groupBy(\"group\").agg(\n",
        "    sum(\"amount\").alias(\"total_amount\"),\n",
        "    avg(\"amount\").alias(\"avg_amount\")\n",
        ").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1y-7g642u9J8",
        "outputId": "87480629-bdd1-49d1-ca6c-3e1bc6931229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------------+----------+\n",
            "|group|total_amount|avg_amount|\n",
            "+-----+------------+----------+\n",
            "|    A|         300|     150.0|\n",
            "|    B|         700|     350.0|\n",
            "|    C|         500|     500.0|\n",
            "+-----+------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7.4 Partition & Shuffle (c·ª±c quan tr·ªçng cho Dataproc sau n√†y)"
      ],
      "metadata": {
        "id": "9mZvhCJj1eyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Partition & Shuffle (c·ª±c quan tr·ªçng cho Dataproc sau n√†y)\n",
        "\n",
        "df.rdd.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aPV8BErvetI",
        "outputId": "8de6e97c-9807-4e46-eb55-a8413f62c7eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.repartition(4, \"group\").rdd.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asofdbWevlla",
        "outputId": "96b6b200-331b-4ded-803f-f0f19a60dd78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7.5 Write Data (gi·ªëng Bronze/Silver)"
      ],
      "metadata": {
        "id": "8Wy_fBfb1hZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write Data (gi·ªëng Bronze/Silver)\n",
        "df.write.mode(\"overwrite\").parquet(\"/content/output/orders\")"
      ],
      "metadata": {
        "id": "SpWB-Eccvql-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.read.parquet(\"/content/output/orders\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EF-_suZBv4lz",
        "outputId": "92cc4684-5d74-4dfd-c344-f55bb89b009c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+------+\n",
            "| id|group|amount|\n",
            "+---+-----+------+\n",
            "|  3|    B|   300|\n",
            "|  4|    B|   400|\n",
            "|  5|    C|   500|\n",
            "|  1|    A|   100|\n",
            "|  2|    A|   200|\n",
            "+---+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß† 1Ô∏è‚É£ Shuffle l√† g√¨\n",
        "\n",
        "### üîπ ƒê·ªãnh nghƒ©a ng·∫Øn g·ªçn\n",
        "\n",
        "**Shuffle** l√† qu√° tr√¨nh Spark ph·∫£i di chuy·ªÉn d·ªØ li·ªáu gi·ªØa c√°c executor/partition ƒë·ªÉ s·∫Øp x·∫øp l·∫°i d·ªØ li·ªáu.\n",
        "\n",
        "> üëâ Shuffle = ch·∫≠m + t·ªën CPU + t·ªën network + t·ªën ti·ªÅn (tr√™n cloud)\n",
        "\n",
        "### üîπ Khi n√†o shuffle x·∫£y ra:\n",
        "\n",
        "|Operation|C√≥ shuffle kh√¥ng?|\n",
        "|---------|-----------------|\n",
        "|filter|‚ùå Kh√¥ng|\n",
        "|select|‚ùå Kh√¥ng|\n",
        "|withColumn|‚ùå Kh√¥ng|\n",
        "|groupBy|‚úÖ C√≥|\n",
        "|join (th∆∞·ªùng)|‚úÖ C√≥|\n",
        "|orderBy|‚úÖ C√≥|\n",
        "|distinct|‚úÖ C√≥|\n",
        "|repartition()|‚úÖ C√≥|\n",
        "|coalesce()|‚ùå Kh√¥ng (n·∫øu gi·∫£m partition)|\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ V√≠ d·ª• tr·ª±c quan\n",
        "\n",
        "```mermaid\n",
        "flowchart LR\n",
        "    A[Partition 1] -->|shuffle| D[New Partition A]\n",
        "    B[Partition 2] -->|shuffle| E[New Partition B]\n",
        "    C[Partition 3] -->|shuffle| F[New Partition C]\n",
        "```\n",
        "\n",
        "> üëâ Spark ph·∫£i gom d·ªØ li·ªáu c√πng key v·ªÅ c√πng partition\n",
        "\n",
        "### üîπ Quy t·∫Øc v√†ng\n",
        "\n",
        "> ‚ùó √çt shuffle = job ch·∫°y nhanh h∆°n r·∫•t nhi·ªÅu\n"
      ],
      "metadata": {
        "id": "hYhewM0Y17Zm"
      }
    }
  ]
}